\chapter{A Quick Overview of Other Tools}




%-------------------------------------------------------------------
%-------------------------------------------------------------------
%-------------------------------------------------------------------

\section{Developing raw and jpeg Images with Devlop}


%-------------------------------------------------------------------
%-------------------------------------------------------------------
%-------------------------------------------------------------------

\section{Making Ortho Mosaic with Porto}
\label{Porto}

\subsection{Introduction}

{\tt Porto}  is a tool for generating a complete mosaic from a set of \UNCLEAR{single}
ortho images generated by {\tt MicMac}. It is in a very basic state,
a lot of improvement would be required. By the way, I think  it can
still be useful for several applications.

To generate the tool:

\begin{center}
     make -f MakeOrtho
\end{center}

{\tt Porto} expects a parameter file like {\tt MicMac} and {\tt Apero}. It
must contain a structure {\tt CreateOrtho} as specified in {\tt SuperposImage.xml}.

The {\tt ExempleDoc/Boudha} data set contains an example of usage. Run it
by typing:

\begin{center}
                  bin/Porto ../micmac\_data/ExempleDoc/Boudha/ORTHO/Param-Porto.xml
\end{center}

   % - - - - - - - -  -- -  - - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - -

\subsection{Input to Porto}

The figure~\ref{Resul:Ortho:MM} presents the output of {\tt MicMac} that is used as
input to {\tt Porto}.
The input to {\tt Porto} consists of:

\begin{itemize}

   \item   a global meta-data  file specifying the geo-referencing of the
           DTM associated to the ortho;

  \item  a set of individual ortho-images;

  \item a set of mask images specifying for each ortho which images are visible;

  \item a set of incidence images, specifying the \UNCLEAR{priority};

  \item  a set of XML meta-data  associated to each image.
\end{itemize}


Figure~\ref{Indiv:Ortho} presents some individual ortho-images computed by MicMac on the
Buddha data set. The figure~\ref{Pb:Indiv:Ortho} presents some details of
the problems of each individual ortho-images. Figure~\ref{Incid:Ortho}
presents the incidence images.






\begin{figure}
\begin{tabular}{||c|c|c||}
   \hline \hline
   \includegraphics[width=55mm]{FIGS/Boudhas/Ort_IMG_5588.jpg}   &
   \includegraphics[width=55mm]{FIGS/Boudhas/Ort_IMG_5589.jpg}   &
   \includegraphics[width=55mm]{FIGS/Boudhas/Ort_IMG_5592.jpg}   \\ \hline  \hline
\end{tabular}
\label{Indiv:Ortho}
\caption{Three of the five individual ortho images}
\end{figure}



\begin{figure}
\begin{tabular}{||c|c||}
   \hline \hline
   \includegraphics[width=80mm]{FIGS/Boudhas/PB-Ort_IMG_5591.jpg}   &
   \includegraphics[width=80mm]{FIGS/Boudhas/PB-Ort_IMG_5592.jpg}   \\ \hline  \hline
\end{tabular}
\label{Pb:Indiv:Ortho}
\caption{Zoom on some problems of  individual ortho-image}
\end{figure}



\begin{figure}
\begin{tabular}{||c|c|c|c|c||}
   \hline \hline
   \includegraphics[width=30mm]{FIGS/Boudhas/Incid_IMG_5588_8Bits.jpg} &
   \includegraphics[width=30mm]{FIGS/Boudhas/Incid_IMG_5589_8Bits.jpg} &
   \includegraphics[width=30mm]{FIGS/Boudhas/Incid_IMG_5590_8Bits.jpg} &
   \includegraphics[width=30mm]{FIGS/Boudhas/Incid_IMG_5591_8Bits.jpg} &
   \includegraphics[width=30mm]{FIGS/Boudhas/Incid_IMG_5592_8Bits.jpg} \\ \hline  \hline
\end{tabular}
\label{Incid:Ortho}
\caption{ Incidence images computed for ortho priority}
\end{figure}

In the example {\tt Param-Porto.xml}, the section specifying these inputs is:


{\scriptsize
\begin{verbatim}
    <SectionEntree>
           <FileMNT> ../MEC-7-Ter/Z_Num5_DeZoom1_LeChantier.xml </FileMNT>
           <KeySetIm>  NKS-Set-OfPattern@Ort_(.*)\.tif </KeySetIm>
           <KeyAssocMetaData > NKS-Assoc-ChangPrefixAndExt@Ort_@tif@PC_@xml  </KeyAssocMetaData>
           <KeyAssocNamePC >   NKS-Assoc-ChangPrefixAndExt@Ort_@tif@PC_@tif </KeyAssocNamePC>
           <KeyAssocNameIncH>  NKS-Assoc-ChangPrefixAndExt@Ort_@tif@Incid_@tif </KeyAssocNameIncH>
    </SectionEntree>
\end{verbatim}
}

The {\tt <FileMNT>} is an XML-meta-data file containing information about the DTM produced
by {\tt MicMac}. Its tags have been described in~\ref{Ex:GrTer:RA}. The ortho-mosaic produced
by {\tt Porto} will have the same geo-referencing as the DTM. The other arguments are
keys for describing sets and associations. The functioning is quite classical now:

\begin{itemize}
    \item {\tt <KeySetIm>} describes the set of individual ortho images;
    \item {\tt <KeyAssocMetaData>} is a key for computing the name of XML-Meta data from the name of individual ortho image;
    \item {\tt <KeyAssocNamePC>} is a key for computing the name of the \UNCLEAR{hidden part image} from the name of individual ortho image;
    \item {\tt <KeyAssocNameIncH>} is a key for computing the name of the incidence image from the name of individual ortho image;

    \item \UNCLEAR{this is the same key}, that is used with different parameters; this key allows to change the
          beginning (prefix) of a name and its extension.

\end{itemize}

Here is {\tt PC\_IMG\_5588.xml}, an example of one of the meta-data file:


{\scriptsize
\begin{verbatim}
<MetaDataPartiesCachees>
     <Done>true</Done>
     <Offset>0 0</Offset>
     <Sz>676 960</Sz>
     <Pas>1</Pas>
     <SeuilUse>3</SeuilUse>
     <SsResolIncH>10</SsResolIncH>
</MetaDataPartiesCachees>
\end{verbatim}
}

The important tags are:

\begin{itemize}
   \item {\tt <Offset>} and {\tt <Sz>} specify the position of the individual ortho-photo
         on the DTM. Because, of course, in real example, the individual ortho-photo  will be much smaller
         than the DTM or resulting mosaic, so it will be stored only a sub-rectangle of the global DTM;

   \item {\tt <SeuilUse>} is a real value, use \UNCLEAR{to threshold} the  images ({\tt PC\_IMG\_5588.tif} \dots) and
         defining which pixel must be used;

   \item {\tt <SsResolIncH>} is the resolution of incidence images ({\tt Incid\_IMG\_5588.tif} \dots)
         in fact as these images are very regular, it would be useless to store them at full resolution.

\end{itemize}


As this file have been generated automatically by {\tt MicMac}, in most cases you will
not need to modify it, but it is still good to understand a bit how things work,
in case of problems \dots


   % - - - - - - - -  -- -  - - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - -

\subsection{Output to Porto}

Once  all these inputs are \UNCLEAR{known}, %nom ou adjectif?
the mosaicing
algorithm is quite obvious:

\begin{itemize}
     \item for each pixel of  the output image:
     \begin{itemize}
          \item select the unmasked image having the lowest incidence.
     \end{itemize}
\end{itemize}

The parameters specifying the output are:

{\scriptsize
\begin{verbatim}
     <SectionSorties>
           <SzDalle>    1000            </SzDalle>
           <SzBrd>      100             </SzBrd>
           <NameOrtho>  Ortho-NonEg-Test-Redr.tif </NameOrtho>
           <NameLabels>  Label-Test-Redr.tif</NameLabels>
     </SectionSorties>
\end{verbatim}
}

{\tt NameOrtho} specifies the name of the ortho mosaic. {\tt NameLabels} is an optional
argument, when specified, {\tt Porto} creates a label image indicating for each pixel which
individual  image is to be used for \UNCLEAR{filling the geometry}.  \UNCLEAR{Figure~\ref{Resul:Ortho}} %pas bon le nr de la fig
presents the main results.


\begin{figure}
\begin{tabular}{||c|c||}
   \hline \hline
   \includegraphics[width=80mm]{FIGS/Boudhas/Label-Test-Redr.jpg}   &
   \includegraphics[width=80mm]{FIGS/Boudhas/Ortho-NonEg-Test-Redr.jpg}   \\ \hline  \hline
\end{tabular}
\label{Resul:Ortho}
\caption{Computed label images and resulting ortho images}
\end{figure}



   % - - - - - - - -  -- -  - - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - -

\section{V.O.D.K.A.}
\label{V.O.D.K.A.}

\subsection{Theory}

The vignetting is an optical effect that results in a gradual radial drop-off in images (the corners of images are relatively darker than the center). The figure (\ref{image_vignette}) shows an example of this effect.

\begin{figure}[htb]
\centering
\includegraphics[width=6cm]{FIGS/Arsenic/595px-Swanson_tennis_center.jpg}
\includegraphics[width=6cm]{FIGS/Arsenic/London_eye_501588_fh000038.jpg}
\caption{
Different vignetting effect
%Vignette from the Nikkor 18-105 mm VR, F/3.6,18mm, fixed on a Nikon D90. The image is one of an homogeneous grey field
}
\label{image_vignette}
\end{figure}

Read more about vignetting :
\begin{itemize}
   \item \url{http://en.wikipedia.org/wiki/Vignetting}
   \item \url{http://fr.wikipedia.org/wiki/Vignettage}
\end{itemize}

\subsection{Name and function}
Vodka stands for "\textit{Vignette Of Digital Kamera Analysis}".

This command estimates the vignetting effect for a set of images with the same aperture and focal length without the need of a laboratory setup (classically an integrating sphere). The vignette model that is used is an even 6th degree polynomial function centered on the middle of the image. With r the distance to the center of the image and $\alpha$, $\beta$ and $\gamma$ the polynomial coefficients, we have : \[V(r)=1+ \alpha r^2 + \beta r^4 + \gamma r^6\]


The computation of the model uses a RANSAC based algorithm to solve the sets of equation of the following type (where $G_{i}$ is the grey value of a tie point for the image i and r the distance to the center of the image) : \[ G_{1}-G_{2}=\alpha(G_{2}*r_{2}^2-G_{1}*r_{1}^2)+\beta(G_{2}*r_{2}^4-G_{1}*r_{1}^4)+\gamma(G_{2}*r_{2}^6-G_{1}*r_{1}^6) \]

Between 9 and 30 points are randomly selected from the tie points and a solution is computed using least square matching. The solution is then awarded a score : \[Score=\frac{P_{inliers}}{EMP}\].

Where:
\begin{itemize}
\item \textit{$P_{inliers}$} the percentage of the tie points complying with the model ($\pm 2\%$) $\Rightarrow$ for good models, a value about 20\% to 40\% is expected.

\item \textit{EMP} the mean error between the model and the points weighted by $min(r_{1},r_{2})$ to increase the importance of points away from the image center (and therefor more influenced by vignetting).
\end{itemize}


\subsection{Input data}
To use this command, a set of images with the same aperture and focal length, taken in a stable illumination setting is necessary. The command also requires the computation of tie points (through Tapioca).


Calling the command is done with the following command line (where ImagesPattern is the regular expression describing the set of images ) : \[mm3d\;Vodka\;ImagesPattern\]

Multiple datasets can be processed at once, the program would then sort the images in subsets with the same aperture and focal length and give a solution for each subset.

\subsection{Output data}
For each aperture/focal length combination in the input set, the commands create a floating point .tif file of the image's size named Vignette/Foc0000Dia111.tif, where 0000 is the focal length in millimeters and 111 the aperture times 10.


Corrected images can also be created if asked by the user, mostly for quality checking (see bellow).


\subsection{Options}
\begin{itemize}
\item{\textit{DoCor (bool)} toggle the creation of corrected images (Def=false)}
\item{\textit{InCal (string)} Name of folder with vignette calibration tif file (if previously computed)}
\item{\textit{InTxt (string)} True if homologous points have been exported in txt (Def=false)}
\item{\textit{Out (string)} Output folder (Default=Vignette)}
\end{itemize}

\subsection{How to use VODKA}
Vodka is to be used to compute a vignette calibration. The best results are obtained with images where tie points are at different distances from the image center in the images that generated them, typically non-convergent images.


The output files should then be placed in a folder with other images taken with the same camera and the same aperture/focal length combination. The images that will be created in the Tmp-MM-Dir (and therefor used by every other commands) when the proper VODKA output files are present will be corrected using those files. If you want to use the VODKA results on the images used to compute it, you should place the VODKA output files in the images' directory and delete the Tmp-MM-Dir folder.

\section{A.R.S.E.N.I.C}
\label{A.R.S.E.N.I.C.}
\subsection{Name and function}
ARSENIC stands for \textit{Automated Radiometric Shift Equalization and Normalization for Inter-image Correction}.


This function corrects the key images used for coloring point clouds in order to have a smooth transition between sub-clouds of the same scene. It is designed to be used with the "GeomImage" correlation geometry.


\textcolor{red}{ This function is not designed for the equalization of images prior to image mosaicing}

\subsection{Input data}
\label{inputArsenic}

ARSENIC require a depth map for each image that will be equalized, computed with MICMAC/Malt. The dense radiometric tie point algorithm used in this program requires very well co-registered depth maps (or point clouds).
Calling the command is done with the following command line (where ImagesPattern is the regular expression describing the set of images ) :\[mm3d\;Arsenic\;ImagesPattern\]

\subsection{Output data}
The output of this command is the corrected images, by default in a folder called Arsenic. These images can then be used to color a point cloud through Nuage2Ply.

\subsection{Options}
\begin{itemize}
\item{\textit{TPA (Tie Point Accuracy - int)} defines the precision threshold for the tie points (def=16, means $\frac{1}{16}$ of pixel resolution)}
\item{\textit{ResolModel (int)} defines the resolution of the model to be used in the tie point computation (def=16 for DeZoom 16)}
\item{\textit{InVig (string)} defines a vignette calibration folder (if any)}
\item{\textit{Out (string)} defines the output directory}
\item{\textit{NbIte (string)} defines the number of iterations of the process (def=5)}
\item{\textit{ThreshDisp (string)} defines the disparity threshold between the tie points (Def=1.4 for 40\%)}
\end{itemize}

\subsection{Algorithm}

\subsubsection{Tie point detection}

In order to have a more accurate, denser and more interest-zone focused set of tie points, the tie points are extracted from the result of the dense correlation.


 Every point situated in the mask of a key image is projected in 3D through the depth map generated by MICMAC/Malt, then reprojected in the other key images and finally projected again in 3D if the second projection resulted in a point in the secondary key image's mask. If the two 3D projections result in a similar point (the concept of similarity being defined through the TPA option : the maximum distance between two 3D projections that validates the points being $PixelResolution/TPA$). For each validated point, the image coordinates of the point in the key image is recorded, as well as the factors $K$ between the pixel values of each images for all channels : \[K=(1+G_{j})/2*G_{i}\]
 With \textit{G} a grey value, \textit{i} the primary key image and \textit{j} the secondary image that generated the tie point. A tie point is therefor an object with 5 values, $Point=(X,Y,K_{R},K_{G},K_{B})$. The $+1$ is a call to the initial value.

\subsubsection{Equalization}

In a first step, a correction factor is computed for each tie point with an inverse distance weighting and a self weighting value (the image is self influencing). For each radiometric channel of each point, $j$, we have the following formula ($i$ is the tie point currently used in the interpolation):
\[Cor(TiePointj)=\sum_{i=1}^{n} \frac{(K_{i})/2}{\sqrt{(X_{i}-X_{j})^2+(Y_{i}-Y_{j})^2}}\]

This process is then iterated. A filtering system is yet to be developed to prevent radiometric outliers to push the model after too many iterations. An outlier is a point where Kr, Kg or Kb is more than \textit{ThreshDisp}\% different than the average value for the image considered.


The corrected tie points are then applied to a grid also through inverse distance weighting, the interpolated to the whole image through bilinear interpolation. The grid is computed by the formula bellow, with $i$ the tie point index and $(X,Y)$ the grid point's coordinates : \[Cor(X,Y)=\sum_{i=1}^{n} \frac{K_{i}}{\sqrt{(X_{i}-X)^2+(Y_{i}-Y)^2}}\]

\begin{figure}[H]
\centering
\includegraphics[width=15cm]{FIGS/Arsenic/SurfCorr.png}
\caption{Example of a correction surface}
\label{SurfCorr}
\end{figure}


\subsection{How to use ARSENIC}

Once the appropriate input data (see~\ref{inputArsenic}) is computed, the command can be run. The images produced in the output folder are to be used as "Attr" arguments in the "Nuage2Ply" command to produce equalized sub-point clouds.

%***************************%
\section{Miscellaneous tools}

%------------------------%
\subsection{TestLib PackHomolToPly}
Tool use to display a tie points between 2 image in 3D. By combination with a mesh 3D, we can examine where tie point is founded on object surface.
Inputs:
\begin{itemize}
\item 2 image that have homol pack - write as pattern (Ex: "image1.tif|image2.tif")
\item Orientation of image
\item SH : Select Homol folder of tie point. Default is "Homol/"
\item color : select color in RGB od tie point. Not so necessary because with the viewer like Cloud Compare, user can change color also.
\end{itemize}
\textit{Attention:} Output is PLY file format, store in \textbf{PlyVerify/} folder.

\begin{verbatim}
********************************************************
*        Draw a pack of homologue in 3D PLY            *
********************************************************
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Pattern of images - 2 image have a pack}
  * string :: {Input Initial Orientation}
Named args : 
  * [Name=SH] string :: {homol folder name - default = Homol}
  * [Name=color] vector<std::string> :: {[R,B,G] - default = [0,255,0]}

\end{verbatim}
\textit{Example:}
\textbf{mm3d MeshProjOnImg BIN\_010-011[1-4].*.tif Ori-BasculeIGN-sec01-21/ meshSimpleCut.ply}

\begin{figure}[H]
\centering
\includegraphics[width=15cm]{FIGS/MeshProjOnImg/TiePOnMesh.jpeg}
\caption{Draw tie point on mesh.}
\label{SurfCorr}
\end{figure}


%------------------------%
\subsection{MeshProjOnImg}
Tool use to back-project a mesh 3D on image 2D. Useful to specify which part of image is covered by the mesh.
Inputs:
\begin{itemize}
\item Pattern of image to examine.
\item Orientation of image
\item Mesh file.

\item zoomF : Zoom factor. Use to reduce image resolution to display. With image too big, display will cause program error. Default is 0.2, that's mean image is reduced to 1/5 of its size original.
\item click : Draw each triangle on mesh on image by mouse click. Each click will draw 1 triangle of mesh.
\end{itemize}
\textit{Attention:} Command will display all image of pattern at the same time, then reproject mesh on first image. You must click on first image to continue reproject mesh on second image and so on. When execute, command will read mesh file in and ask user if they like to display all the element in mesh file on the terminal. With "n", we can skip this step.

\begin{verbatim}
********************************************************
*               Reproject mesh on specific 	       *
********************************************************
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Pattern of images}
  * string :: {Input Initial Orientation}
  * string :: {path to mesh(.ply) file - created by Inital Ori}
Named args : 
  * [Name=zoomF] REAL :: {1 -> sz origin, 0.2 -> 1/5 size - default = 0.2}
  * [Name=click] bool :: {true => draw each triangle by each click - default = false}
\end{verbatim}
\textit{Example:}
\textbf{mm3d MeshProjOnImg BIN\_010-011[1-4].*.tif Ori-BasculeIGN-sec01-21/ meshSimpleCut.ply}

\begin{figure}[H]
\centering
\includegraphics[width=15cm]{FIGS/MeshProjOnImg/meshOnImg.jpeg}
\caption{Result reproject mesh on image.}
\label{SurfCorr}
\end{figure}

%------------------------%
\subsection{InitOriLinear}

With {\tt InitOriLinear}, you can initialize your orientation in case of your acqusition is a serie of image with a displacement linear. Tool compute a vector of displacement from a set of reference image, then using it to estimate position of other image in serie.

By using this tool to initialize orientation before compute aero with Tapas, computation speed is improved.

Inputs:
\begin{itemize}
\item Folder contain orientation of reference images
\item Folder to output orientation file
\item Pattern of image need to initialize. If your system have many camera ona bar rigide, you can give pattern correspondant with each camera, seperate by ",".
\item Pattern of image use for reference. Idem if system have many camera. Order of camera must be the same.

\item PatTurn : Turn image when direction of acquisition changed.(new section) (image of 1st camera)
\item PatAngle : Turn angle correspondant with each turn image. Positive value for turn left, negative for turn right.
\item mulF : multiplication factor to adjustment position between each section (use to spread or shorten distance between section)
\item Axe : axe to turn around.
\end{itemize}

The output is orientation files initialized. Can be use as an initialized solution for {\tt Tapas} with option {\tt InOri}

\begin{verbatim}
mm3d InitOriLinear -help
************************
*  X : Initial         *
*  X : Orientation     *
*  X : & Position      *
*  X : For Acquisition *
*  X : Linear          *
************************
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Ori folder of reference images}
  * string :: {Folder for output initialized orientation- default = Ori-InitOut}
  * string :: {Pattern of new images to orientate PatCam1, PatCam2,..}
  * string :: {Pattern of Reference Image = PatRef1, PatRef2,..}
Named args : 
  * [Name=PatTurn] vector<std::string> :: {Images when acquisition have turn [poseTurn1,poseTurn2...]}
  * [Name=PatAngle] vector<std::string> :: {Turn angle [angle1,angle2,...] - + => turn left, - => turn right}
  * [Name=mulF] vector<std::string> :: {Multiplication factor for adjustment each turn [mul1,mul2,...]}
  * [Name=Axe] string :: {Which axe to calcul rotation about - default = z}
  * [Name=WithIdent] bool :: {Initialize with orientation identique (default = false)}
  * [Name=Plan] bool :: {Force using vector [0,0,1] to initialize (garantie all poses will be in a same plan) - (default = false)}
\end{verbatim}

\underline{\textit{\textbf{Example:}}}

An acqutision with 3 section continue. Each section is seperate by a turn. Section 1, then turn left 90° to section 2, then turn left 45° to section 3 (Fig 7.7). Acqusition is done by a system 2 camera on a bar rigide.
Name image is contain an indicator of camera:
\begin{verbatim}
For camera 1: BIN_.*_image_023_.*.tif
For camera 2: BIN_.*_image_024_.*.tif
\end{verbatim}
Two turns in acqusition: 
\begin{verbatim}
Turn 1 : 90° left at image BIN_010-0120_14576019095_image_023_001_01316.thm.tif
Turn 2 : 45° left at image BIN_021-0150_14576061046_image_023_003_02935.thm.tif
\end{verbatim}

\underline{\textit{\textbf{Step 1:}}} orientate some images as a reference. Select image from 2 camera, in same shot to compute relative position between cameras and vector of displacement.
\begin{verbatim}
mm3d Tapas FishEyeBasic "BIN_010-011[1-2].*.tif" Out=reference
\end{verbatim}
We have an aero of reference image as show on Fig7.8.

\underline{\textit{\textbf{Step 2:}}} Initialize another image. We have 2 serie correspondant with 2 camera, and we have 2 turn. By using command {\tt InitOriLinear}:
\begin{verbatim}
mm3d InitOriLinear Ori-reference Ori-InitOut \
    "BIN_0.*-(011[4-9]|01[2-6]).*_023.*.tif,BIN_0.*-(011[4-9]|01[2-6]).*_024.*.tif" \
    "BIN_010-011[1-3].*_023.*.tif,BIN_010-011[1-3].*_024.*.tif" \
    PatTurn=[BIN_021-0128_14576060714_image_023_003_02913.thm.tif, \
             BIN_021-0148_14576061016_image_023_003_02933.thm.tif] \
    PatAngle=[90,45] mulF=[1,1] Axe=z
\end{verbatim}

In the command, we use orientation reference in Ori-reference, we have 2 pattern correspondant with 2 camera, first is 023 and seconde is 024. Acquisition turned at pose "BIN\_021-0128\_14576060714\_image\_023\_003\_02913.thm.tif" and "BIN\_021-0148\_14576061016\_image\_023\_003\_02933.thm.tif" with angle correspondant is 90° and 45°. Attention: number of image in each serie must be the same, and image to indicate a turn must be image of the first camera.
Result is shown on Fig7.8 and Fig7.9

\begin{figure}[H]
\centering
\includegraphics[width=4cm]{FIGS/InitOriLinear/planpartir_quartier.png}
\caption{Plan of acquisition linear with 2 turn, 3 section}
\label{SurfCorr}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=10cm]{FIGS/InitOriLinear/InitPose01.png}
\caption{Calcul aero of reference image. System with 2 camera}
\label{SurfCorr}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=10cm]{FIGS/InitOriLinear/InitAllImg2Turn00.png}
\caption{Result initialize oritentation of linear acquisition}
\label{SurfCorr}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=10cm]{FIGS/InitOriLinear/InitAllImg2Turn01.png}
\caption{System with 2 camera}
\label{SurfCorr}
\end{figure}

%--------------------%
\subsection{ReprojImg}

With {\tt ReprojImg}, you can project an image into the orientation of an other.

Inputs:
\begin{itemize}
\item Ori of all images
\item correlation directory with reference image DEM
\item reference image name
\item name of image to reproject
\end{itemize}

The output is the image reprojected into reference orientation.

\begin{verbatim}
mm3d ReprojImg -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Directory of input orientation}
  * string :: {Reference DEM filename}
  * string :: {Reference image name}
  * string :: {Name of image to reproject}
Named args : 
  * [Name=AutoMask] string :: {AutoMask filename}
\end{verbatim}

As an example, when we have many pictures of first epoch (epoque1.*), we create a DEM,
then we can compute the orientation of an image of an other epoch (epoque2\_a.JPG) in the same reference,
and finally we reproject it in the (epoque1\_f.JPG) geometry :
\begin{verbatim}
mm3d Tapioca All "epoque1_..JPG" -1
mm3d Tapas RadialBasic "epoque1_..JPG"
mm3d Malt GeomImage "epoque1_..JPG" RadialBasic Master="epoque1_f.JPG" EZA=1

mm3d Tapioca All "epoque._..JPG" -1
mm3d Tapas RadialBasic "epoque._..JPG" InOri=RadialBasic  Out=Tout

mm3d ReprojImg Ori-Tout/ MM-Malt-Img-epoque1_f/Z_Num8_DeZoom1_STD-MALT.tif \
               epoque1_f.JPG epoque2_a.JPG
\end{verbatim}

%--------------------------%
\subsection{ExtractMesure2D}
The {\tt ExtractMesure2D} command extracts only a selection of targets in a 2D measures file. Its main purpose is to split images measures into used and check targets.

\begin{verbatim}
mm3d ExtractMesure2D -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Input mes2D file}
  * string :: {Output mes2D file}
  * vector<std::string> :: {List of selected targets. Ex: [target1,target2])}
Named args : 
\end{verbatim}

Example:
\begin{verbatim}
mm3d ExtractMesure2D 21pts_Mesure-S2D.xml out.xml [3,203]
\end{verbatim}
Will save in out.xml only the 2D measures for targets 3 and 203.

%------------------------------%
\subsection{BasculeCamsInRepCam}
The {\tt BasculeCamsInRepCam} command express all images external parameters whith respect to the camera frame of one chosen image.

\begin{verbatim}
mm3d TestLib BasculeCamsInRepCam -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Full Name (Dir+Pattern)}
  * string :: {Orientation}
  * string :: {Central camera}
  * string :: {Output}
\end{verbatim}

Example :
\begin{verbatim}
mm3d TestLib BasculeCamsInRepCam ".*JPG" Ori-AutoCal/ IMG00004.JPG Img04
\end{verbatim}

In {\tt Ori-Img04/} one can check that external parametrs of image {\tt IMG00004.JPG} are by definition equal to identity matrix.

%-----------------------------%
\subsection{BasculePtsInRepCam}
The {\tt BasculePtsInRepCam} command express coordinates of input points with respect to the camera frame of one chosen image.

\begin{verbatim}
mm3d TestLib BasculePtsInRepCam -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Name Camera}
  * string :: {Name GGP In}
Named args : 
  * [Name=Out] string
\end{verbatim}

Example :
\begin{verbatim}
mm3d TestLib BasculePtsInRepCam Ori-AutoCal/Orientation-IMG00004.JPG.xml App.xml
\end{verbatim}

Output file {\tt Basc-Orientation-IMG00004.JPG-App.xml} contains points coordinates expressed in the camera frame of {\tt IMG00004.JPG}.

%-----------------%
\subsection{CorrLA}
The {\tt CorrLA} command computes corrected images positions with respect to a given value of lever-arm offset.

\begin{verbatim}
mm3d TestLib CorrLA -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Full Name (Dir+Pattern)}
  * string :: {Directory orientation}
  * Pt3dr :: {Lever-Arm value}
Named args : 
  * [Name=OriOut] string :: {Output Ori Name of corrected mandatory Ori ; Def=OriName-CorrLA}
  * [Name=Ori2] string :: {Ori2 directory to apply LA correction to centers}
  * [Name=Ori2Out] string :: {Output Ori Name of corrected Ori2 ; Def=Ori2Name-CorrLA}
\end{verbatim}

Example:
\begin{verbatim}
mm3d TestLib CorrLA ".*JPG" Ori-Basc/ [0.289,-0.043,-0.183] Ori2=Ori-Nav-GPS/
\end{verbatim}

Sometimes, it is more accurate to compute the lever-arm correction and to apply it to a second set of images positions.
Using the optional argument {\tt Name=Ori2} one can apply corrections calculated with the orientations from the mandatory {\tt Ori-Basc/} and generate {\tt Ori-Nav-GPS-CorrLA/} with
lever-arm corrected positions. 

%---------------------------%
\subsection{ExportXmlGcp2Txt}
The {\tt ExportXmlGcp2Txt} command simply convert a GCP .xml file format into a column format text file.

\begin{verbatim}
mm3d TestLib ExportXmlGcp2Txt -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Directory}
  * string :: {xml Gcps file}
Named args : 
  * [Name=Out] string :: {output txt file name : def=Output.txt}
  * [Name=addInc] bool :: {export also uncertainty values : def=flase}
\end{verbatim}

Example :
\begin{verbatim}
mm3d TestLib ExportXmlGcp2Txt './' AppAll.xml Out=AppAll-Txt.txt
\end{verbatim}

This command can be useful for example when a GCP file is converted to .xml format using {\tt mm3d GCPConvert} with a change of system and the user wants to recover transformed coordinates in a simple format.


%------------------------%
\subsection{SimplePredict}
The {\tt SimplePredict} command projects ground points on oriented images.

\begin{verbatim}
mm3d SimplePredict -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Pattern of images}
  * string :: {Directory orientation}
  * string :: {Ground points file}
Named args : 
  * [Name=ExportPolyIGN] bool :: {Export PointeInitIm files for IGN Polygon calibration method (Def=false)}
  * [Name=PrefixeNomImageSize] INT :: {Size of PrefixeNomImage in param.txt}
\end{verbatim}

Example :
\begin{verbatim}
mm3d SimplePredict ".*JPG" Ori-Basc/ AppAll.xml
\end{verbatim}

The output {\tt SimplePredict.xml} file contains (i,j) coordinates of all {\tt AppAll.xml} points in all possible images.

%---------------------%
\subsection{Export2Ply}
The {\tt Export2Ply} command generates a .ply file containing spheres to represent points.

\begin{verbatim}
mm3d TestLib Export2Ply -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Format specification}
  * string :: {Name File of Points Coordinates}
Named args : 
  * [Name=Ray] REAL :: {Plot a sphere per point}
  * [Name=NbPts] INT :: {Number of Pts / direc (Def=5, give 1000 points) only with Ray > 0}
  * [Name=Scale] INT :: {Scaling factor}
  * [Name=FixColor] Pt3di :: {Fix the color of points}
  * [Name=LastPtColor] Pt3di :: {Change color only for last point}
  * [Name=ChangeColor] INT :: {Change the color each number of points : not with FixColor}
  * [Name=Out] string :: {Default value is NameFile.ply}
  * [Name=Bin] INT :: {Generate Binary or Ascii (Def=1, Binary)}
\end{verbatim}

Example :
\begin{verbatim}
mm3d TestLib Export2Ply "#F=N_X_Y_Z" AppAll-Txt.txt Ray=0.5 FixColor=[0,0,255]
\end{verbatim}

This is sometimes useful for example when one wants to represent GCPs into a point cloud to clearly visualize its distribution.

%-----------------%
\subsection{CmpOri}
The {\tt CmpOri} command computes average norme differences of all external parametrs of images.

\begin{verbatim}
mm3d CmpOri -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Full Name (Dir+Pattern)}
  * string :: {Orientation 1}
  * string :: {Orientation 2}
Named args : 
  * [Name=DirOri2] string :: {Orientation 2}
  * [Name=XmlG] string :: {Generate Xml}
\end{verbatim}

Example :
\begin{verbatim}
mm3d CmpOri ".*JPG" Ori-Bascule/ Ori-Compense/ XmlG=Delta_Basc_Comp.xml
\end{verbatim}

For example the result displayed and saved in {\tt Delta\_Basc\_Comp.xml} :
\begin{verbatim}
<?xml version="1.0" ?>
<XmlTNR_TestOriReport>
     <OriName>RTL-Compense-AllPts</OriName>
     <TestOriDiff>false</TestOriDiff>
     <DistCenter>0.0397097570172935677</DistCenter>
     <DistMatrix>3.87112370850761372e-07</DistMatrix>
</XmlTNR_TestOriReport>
\end{verbatim}


%-------------------%
\subsection{CmpCalib}
The {\tt CmpCalib} command compares two files of calibrations (in general of the same camera).

\begin{verbatim}
mm3d CmpCalib -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {First calibration file}
  * string :: {Second calibration file}
Named args : 
  * [Name=Teta01] REAL
  * [Name=Teta02] REAL
  * [Name=Teta12] REAL
  * [Name=L1] INT
  * [Name=SzW] INT
  * [Name=DynV] REAL
  * [Name=Out] string :: {Result (Def=Name1_ecarts.txt)}
  * [Name=DispW] bool :: {Display window}
  * [Name=XmlG] string :: {Generate Xml}
\end{verbatim}

Example :
\begin{verbatim}
mm3d CmpCalib Ori-Bascule/AutoCal_Foc-35000_Cam.xml Ori-Compense/AutoCal_Foc-35000_Cam.xml Out=Delta_Calib.txt
\end{verbatim}

Calibration parameters of a camera can not be directly compared, the command estimates a rotation to align the parameters.
The output file {\tt Delta\_Calib.txt} contains a function which gives the differences between the two sets of calibration as function of the radius and 
a grid which provides planimetric vector deviation between each rays directions. Example of output :

\begin{verbatim}
--------------  Ecart radiaux  -----------
 Rayon   Ecart
 0.000000 0.035861
 200.000000 0.094960
 400.000000 0.184629
 ...
 --------------  Ecart plani  -----------
Im.X Im.Y  PhG.X Phg.Y Ec
5017.600000 3763.200000 -0.855326 -0.588127 1.038015
5017.600000 3394.560000 -0.951363 -0.529560 1.088818
5017.600000 3025.920000 -0.988994 -0.465235 1.092956
...
\end{verbatim}

%--------------------------%
\subsection{PseudoIntersect}
The {\tt PseudoIntersect} command estimates the 3D position coordinates of 2D measured points in oriented images.

\begin{verbatim}
mm3d TestLib PseudoIntersect -help
*****************************
*  Help for Elise Arg main  *
*****************************
Mandatory unnamed args : 
  * string :: {Full Name (Dir+Pat)}
  * string :: {Directory of input orientation}
  * string :: {.xml file of 2d points}
Named args : 
  * [Name=Out] string :: {Name output file (def=3DCoords.txt)}
  * [Name=XmlOut] bool :: {Export in .xml format to use as GCP file (Def=true)}
  * [Name=Show] bool :: {Gives details on arguments (Def=true)}
\end{verbatim}

Example :
\begin{verbatim}
mm3d TestLib PseudoIntersect ".*JPG" Ori-All/ MesuresFinales-S2D.xml
\end{verbatim}

Each point needs to be measured at least in 2 images to compute an intersection.
The output .xml file can be directly used as a GCP file with {\tt GCPBascule} tool.

