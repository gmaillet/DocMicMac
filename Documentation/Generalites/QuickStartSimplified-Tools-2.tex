\chapter{Use cases with Simplified tools}


%-------------------------------------------------------------------
%-------------------------------------------------------------------
%-------------------------------------------------------------------

\section{The Vincennes data set}

%-------------------------------------------------------------------

\subsection{Description of the data set}
\label{Vincennes:DataSet}

On {\tt micmac\_data/ExempleDoc/} the directory {\tt Vincennes} contains
$106$ images of the Vincennes' castle \footnote{they are low resolution images
to limit the  downloading time}. This data set illustrate how
the tools described here can be used to achieve a typical architectural task:
compute for each of the main facade an ortho photo, these ortho photo
must be referenced in the same coordinate system.  Although the ortho-cylindrical
option for geometry described to process this acquisition seems a very specific
and narrow technical case, practically it corresponds to very current case
for facade processing.


The $106$ images of Vincennes' data set are organized in $4$ subset :


\begin{itemize}
   \item  images {\tt Face1.*} correspond to the first facade;
   \item  images {\tt Face2.*} correspond to the second facade;
   \item  images {\tt  Lnk12.*} images acquired to make the link between
           the two facades;
   \item  images {\tt  Calib.*} acquired to have easily a first
           calibration.
\end{itemize}

Note that, \emph{before any processing}, the images have been renamed taking
into account the acquisition structure. It is highly recommended to do the
same thing before processing data sets having some complexity. It avoids
the creation of tricky regular expression. These images are jpeg low resolution
images to limit the bandwidth when one upload the data, but of course in
real case the full resolution raw image will be preferred.


\begin{figure}
\begin{center}
\includegraphics[width=120mm]{FIGS/Vincennes/Planche-F1.jpg}

\vspace{0.3cm}
\includegraphics[width=120mm]{FIGS/Vincennes/Planche-F2.jpg}

\vspace{0.3cm}
\includegraphics[width=120mm]{FIGS/Vincennes/Planche-Lnk.jpg}

\vspace{0.3cm}
\includegraphics[width=120mm]{FIGS/Vincennes/Planche-Calib.jpg}
\end{center}
\caption{Image of Vincenne's data set : Face1, Face2, Lnk12 and Calib }
\label{FIG:Glob:Vincenne}
\end{figure}




The file {\tt  ExeCmd.txt} contains all the commands that we will need to process these images.


%-------------------------------------------------------------------

\subsection{Computing tie points and orientations}

    %  -  -  -  -  -  -  -  -  -  -  -  -

\subsubsection{Tie points}

The computation of tie points and relative orientation is quite
classic now.

For tie points we want to compute:

\begin{itemize}
   \item  points  between all pairs of calibration data set;
   \item  points  of \emph{Face1} and \emph{Face2} using the linear structure of
          the acquisition;
   \item  points  between \emph{Lnk12} and connected subset of  \emph{Face1} and \emph{Face2};
\end{itemize}

This is done by :

\begin{verbatim}
Tapioca All  "Calib-IMGP[0-9]{4}.JPG" 1000
Tapioca Line "Face1-IMGP[0-9]{4}.JPG" 1000 5
Tapioca Line "Face2-IMGP[0-9]{4}.JPG" 1000 5
Tapioca All  "((Lnk12-IMGP[0-9]{4})|(Face1-IMGP529[0-9])|(Face2-IMGP531[0-9])).JPG" 1000
\end{verbatim}

    %  -  -  -  -  -  -  -  -  -  -  -  -

\subsubsection{Relative orientation}

Then we want to make a first calibration with the calibration data set, and
use this calibration as an initial value to the global orientation of
\emph{Face1},  \emph{Face2} and \emph{Lnk12}. This is done by :

\begin{verbatim}
Tapas RadialStd "Calib-IMGP[0-9]{4}.JPG" Out=Calib
Tapas RadialStd "(Face1|Face2|Lnk12)-IMGP[0-9]{4}.JPG" Out=All InCal=Calib
\end{verbatim}

    %  -  -  -  -  -  -  -  -  -  -  -  -

\subsubsection{Optional, absolute orientation}

Finally, we want to transform the orientation from an arbitrary relative
orientation to some physically based orientation. If we have some ground
control points, this can be done using the {\tt GCPBascule} command (see~\ref{Sec:GCPBascule}) . To
generate orientation in {\tt Ori-Ground} :

\begin{verbatim}
GCPBascule  "(Face1|Face2|Lnk12)-IMGP[0-9]{4}.JPG" All Ground Mesure-TestApInit-3D.xml\
 Mesure-TestApInit.xml
\end{verbatim}

    %  -  -  -  -  -  -  -  -  -  -  -  -

\subsubsection{Optional, scene-based orientation}

Alternatively, if we do not have any GCP and want to put the data in an orientation
having some physical meaning, we can use the {\tt SBGlobBascule} command (see~\ref{ScBas:Basc}) :

\begin{verbatim}
SBGlobBascule "(Face1|Face2|Lnk12)-IMGP[0-9]{4}.JPG" All MesureBascFace1.xml  Glob \
    PostPlan=_MasqPlanFace1  DistFS=2.0 Rep=ij
\end{verbatim}

There is a new option {\tt Rep=ij}, the meaning of this option is :
\label{SGB:Rep}

\begin{itemize}
   \item it is a string that describe a repair;
   \item it must contain $2$ symbols, each symbols can be in \emph{\{i,-i,j,-j,k,-k\}} and describe a vector;
   \item the global orientation with be such that in the final orientation the line
         defined by {\tt Line1-Line2} is aligned on first vector, and the normal to the plane is aligned on second vector;
   \item here in final orientation $i$ will be the horizontal of the wall and $j$ will be the
         normal to the wall, consequently $k=i\wedge j$ will be the vertical;
\end{itemize}


%-------------------------------------------------------------------
\subsection{Matching}


    %  -  -  -  -  -  -  -  -  -  -  -  -
\subsubsection{"Standard" option}

The "standard pipeline" for generating an ortho photo of facade,
as seen in~\ref{Simp:Tool:One}, is for each facade :

\begin{itemize}
   \item compute a local repair to define the facade with {\tt RepLocBascule};
   \item compute a rectified image with {\tt Tarama};
   \item make the matching with {\tt Malt};
   \item generate the ortho image with {\tt  Tawny};
\end{itemize}

This can be done by the succession of commands:

\begin{verbatim}
RepLocBascule  "(Face1)-IMGP[0-9]{4}.JPG" Ground  MesureBascFace1.xml Repere-F1.xml\
       PostPlan=_MasqPlanFace1
Tarama  "(Face1)-IMGP[0-9]{4}.JPG" Ground  Repere=Repere-F1.xml  Out=TA-F1 Zoom=4
Malt Ortho  "(Face1)-IMGP[0-9]{4}.JPG"  Ground  Repere=Repere-F1.xml  \
                     SzW=1 ZoomF=1  DirMEC=Malt-F1 DirTA=TA-F1
Tawny Ortho-Malt-F1/
\end{verbatim}

The results are quite deceiving !!! Figure~\ref{FIG:Pb:Vincenne} illustrate the
encountered problem :

\begin{itemize}
    \item on first line, the ortho photo; it suffer several problem; the main problem
         are located on the roof (due to bad incidence angles) and on horizontal lines;

    \item on second line, a snapshot from Meshlab, showing the camera position;
          it illustrates the fact that in this acquisition all the camera centers are
         located on the same line;

    \item the third line, focus on the matching problem  that occurs on linear detail that
          are parallel to the line of acquisition;
\end{itemize}


\begin{figure}
\begin{center}
\includegraphics[width=160mm]{FIGS/Vincennes/Ortho-Moche.jpg}

\vspace{0.3cm}
\includegraphics[width=160mm]{FIGS/Vincennes/CamFace1.jpg}

\vspace{0.3cm}
\includegraphics[width=160mm]{FIGS/Vincennes/MNT-Moche.jpg}

\end{center}
\caption{Problem with standard processing on Vincennes Facade : low quality ortho photo,
aligment of cameras, poor dept map especially for linear structure parallel to camera alignment}
\label{FIG:Pb:Vincenne}
\end{figure}


    %  -  -  -  -  -  -  -  -  -  -  -  -
\subsubsection{"Ortho-cylindrical" option}

Intuitively it  is obvious that when the camera center are all aligned on the same line,
the matching problem is  ambiguous for line parallel to the acquisition, consequently
the quality of result is poor.
Obviously, the default would decrease (in fact disappear) if the camera were not
aligned, using an UAV or a scaffolding , we could have an optimal geometry similar
to aerial acquisition. But it is not always possible to have such material and, for economical reason,
it would be interesting to be able to obtain a relatively good quality ortho photo even when
all the camera are aligned.

In fact for theoretical reasons described in~\cite{Penard},
this problem are  much more important in ground geometry than in image geometry.
With the option we have seen until now, we have basically this alternative:

\begin{itemize}
   \item  use the ground geometry with a simple process but obtain bad quality results such those of
          figure~\ref{FIG:Pb:Vincenne};

   \item  use the image geometry with  good results but have a complicated workflow with many depth map
          that must be merged.
\end{itemize}


With such acquisition, the ortho-cylindrical geometry combine the benefit of these
two geometries. Intuitively this geometry is equivalent to the geometry of a virtual push-broom
camera, the line of this virtual push-broom being the line on which are located the
camera center. More formally :


\begin{itemize}
   \item  let  $X,Y,Z$ be a coordinate system such that $Y=0$ be approximately the line on which the camera
          are located, and $Z=D$ be approximately the plane of the wall;

   \item  let  $U,V,L$ be the coordinate system defined by
\begin{itemize}
    \item  $U= D \tan^{-1} (\frac{X}{Z})$
    \item  $V=Y$ and $L=Z$;
\end{itemize}
   \item   we  will then compute the DSM as a function $L= F(U,V)$.
\end{itemize}

To use this geometry, we just need to set {\tt OrthoCyl=true} in the command {\tt RepLocBascule} :

\begin{verbatim}
RepLocBascule  "(Face1)-IMGP[0-9]{4}.JPG" Ground  MesureBascFace1.xml Ortho-Cyl1.xml\
   PostPlan=_MasqPlanFace1 OrthoCyl=true
\end{verbatim}

With this option, {\tt RepLocBascule} will also compute, using least mean square,
the line that fit the best the alignment of camera perspective centers. If we take
a look at file {\tt Ortho-Cyl1.xml} we can see  this line coded by {\tt <P0>}
and {\tt <P1>}  (plus the previous local repair  {\tt <Repere>}) :

\begin{verbatim}
<XmlModeleSurfaceComplexe>
     <XmlOneSurfaceAnalytique>
          <XmlDescriptionAnalytique>
               <OrthoCyl>
                    <Repere>
                         <Ori>-0.00573  -2.7113574  -0.4521156 </Ori>
                         <Ox>  0.00029   0.9999998  -0.0003715 </Ox>
                         <Oy> -0.00043   0.0003716   0.9999998 </Oy>
                         <Oz>  0.99999  -0.0002960   0.0004372 </Oz>
                    </Repere>
                    <P0>30.392821 -2.720358 -0.438823</P0>
                    <P1>30.391561 -1.720359 -0.43974</P1>
                    <AngulCorr>true</AngulCorr>
               </OrthoCyl>
          </XmlDescriptionAnalytique>
          <Id>TheSurf</Id>
          <VueDeLExterieur>true</VueDeLExterieur>
     </XmlOneSurfaceAnalytique>
</XmlModeleSurfaceComplexe>
\end{verbatim}

    %  -  -  -  -  -  -  -  -  -  -  -  -
\subsubsection{Concrete use of "Ortho-cylindric" option}

It is then sufficient to give the file created by  {\tt RepLocBascule}
as an optional parameter to {\tt Tarama} and {\tt Malt} to compute
in the adequate geometry; for facade one, we can enter:


\begin{verbatim}
RepLocBascule  "(Face1)-IMGP[0-9]{4}.JPG" Ground  MesureBascFace1.xml Ortho-Cyl1.xml \
        PostPlan=_MasqPlanFace1 OrthoCyl=true
Tarama  "(Face1)-IMGP[0-9]{4}.JPG" Ground  Repere=Ortho-Cyl1.xml  Out=TA-OC-F1 Zoom=4
Malt Ortho  "(Face1)-IMGP[0-9]{4}.JPG"  Ground  Repere=Ortho-Cyl1.xml  \
                   SzW=1 ZoomF=1  DirMEC=Malt-OC-F1 DirTA=TA-OC-F1
Tawny Ortho-UnAnam-Malt-OC-F1/
\end{verbatim}

And for facade 2 :

\begin{verbatim}
RepLocBascule  "(Face2)-IMGP[0-9]{4}.JPG" Ground  MesureBascFace2.xml Ortho-Cyl2.xml \
     PostPlan=_MasqPlanFace2 OrthoCyl=true
Tarama  "(Face2)-IMGP[0-9]{4}.JPG" Ground  Repere=Ortho-Cyl2.xml  Out=TA-OC-F2 Zoom=4
Malt Ortho  "(Face2)-IMGP[0-9]{4}.JPG"  Ground  Repere=Ortho-Cyl2.xml  SzW=1 ZoomF=1  \
          DirMEC=Malt-OC-F2 DirTA=TA-OC-F2 NbVI=2
Tawny Ortho-UnAnam-Malt-OC-F2/
\end{verbatim}

Note some options of these commands:

\begin{itemize}
   \item in {\tt RepLocBascule}, the {\tt OrthoCyl=true} as described above;
   \item in {\tt Tarama}, the {\tt Out=TA-OC-F1} (and {\tt Out=TA-OC-F2}) to specify the
         directory of output; this is naturally to avoid that each call to {\tt Tarama} overwrite
         the result of previous calls;
   \item in {\tt Malt}, the {\tt DirTA=TA-OC-F1} to get the adequete entry from  {\tt Tarama}
         and {\tt Out=DirMEC=Malt-OC-F1} to specify the results; this change the place are written
         the results of matching, and also the result of individual ortho photo (here it will be
         {\tt Ortho-UnAnam-Malt-OC-F1/});
\end{itemize}


If the ortho-cylindrical geometry is "optimal" for computation, this is
generally not a proper geometry for the final user , so at the end of the process,
{\tt MicMac} generate an "un-anamorphosed" version of this depth map in
euclidean geometry.  For example on directory {\tt Malt-OC-F1/}, there
exists $9$ files {\tt Z\_NumX\_DeZoomY\_STD-MALT.tif} corresponding to
the different level of matching in ortho-cylindrical geometry,
and a single file {\tt Z\_Num1\_DeZoom1\_Malt-Ortho-UnAnam.tif}
corresponding to the eulidean version of the last file
( this is the version presented on second line of
figure~\ref{FIG:OK:Vincenne}).
Note that in general there will be very few hidden part on
ortho-cylindrical depth map; conversely, they are quite current on
euclidean version, but it is intrinsic to what we want to restituate
with such acquisition.
By default, the ortho photo are also generated in euclidean geometry
using the unanamorphosed depth-map. Here for example, they are
generated under {\tt Ortho-UnAnam-Malt-OC-F1/} and {\tt Ortho-UnAnam-Malt-OC-F2/}.


Figure~\ref{FIG:OK:Vincenne} present some results obtained after this process:

\begin{itemize}
    \item first line present the depth-map computed in ortho-cylindric geometry using
           color code;
    \item  second line, euclidean version of the depth map, remark the hidden part;

    \item  third line, ortho photo of facade.
\end{itemize}

\begin{figure}
\begin{center}
\includegraphics[width=160mm]{FIGS/Vincennes/MNE-OC.jpg}

\vspace{0.3cm}
\includegraphics[width=160mm]{FIGS/Vincennes/MEN-Eucl.jpg}

\vspace{0.3cm}
\includegraphics[width=160mm]{FIGS/Vincennes/Ortho-Eg-Test-Redr.jpg}

\end{center}
\caption{1-Depth map in ortho cylindric geometry, 2-The same, anamorphosed in euclidean
geometry, 3-Ortho photo in euclidean geometry}
\label{FIG:OK:Vincenne}
\end{figure}


Although all the tool described in this section are rather optimized
for ortho-photo generation, it is still possible to generate 3D cloud points.
As usual in ground geometry, we use the result of matching for the 3D and
the ortho-photo for textures.
For example:


\begin{verbatim}
Nuage2Ply Malt-OC-F1/NuageImProf_Malt-Ortho-UnAnam_Etape_1.xml \
      Attr=Ortho-UnAnam-Malt-OC-F1/Ortho-Eg-Test-Redr.tif Scale=3

Nuage2Ply Malt-OC-F2/NuageImProf_Malt-Ortho-UnAnam_Etape_1.xml \
      Attr=Ortho-UnAnam-Malt-OC-F2/Ortho-Eg-Test-Redr.tif Scale=3
\end{verbatim}

The meta data file {\tt NuageImProf\_Malt-Ortho-UnAnam\_Etape\_1.xml} contains
all the information relative to the local repair use for computation  (inside
the {\tt <RepereGlob>} balise):

\begin{verbatim}
<?xml version="1.0" ?>
<XML_ParamNuage3DMaille>
     <NbPixel>5972 1834</NbPixel>
     <PN3M_Nuage>
..
     </PN3M_Nuage>
     <RepereGlob>
          <Ori>-0.00573682224569793675 -2.71135741550217935 -0.452115668474152133</Ori>
          <Ox>0.000296255688442622397 0.999999887087029138 -0.000371562236912849938</Ox>
          <Oy>-0.000437158066873386052 0.000371691728275074906 0.999999835369028367</Oy>
          <Oz>0.999999860562685972 -0.000296093208240548543 0.000437268133301418503</Oz>
     </RepereGlob>
...
  <Orientation>
....
  </Orientation>
...
</XML_ParamNuage3DMaille>
\end{verbatim}

The point cloud are then generated in the same global repair and are
naturally mergeable as can be seen on figure~\ref{FIG:TroidD:Vincenne}.


\begin{figure}
\begin{center}
\includegraphics[width=160mm]{FIGS/Vincennes/Vinc3D.jpg}
\end{center}
\caption{Snapshot of two point clouds of the facade}
\label{FIG:TroidD:Vincenne}
\end{figure}

%-------------------------------------------------------------------
%-------------------------------------------------------------------
%-------------------------------------------------------------------

\section{The Saint-Michel de Cuxa data set}

%-------------------------------------------------------------------

\subsection{Description of the data set}
\label{Cuxa:DataSet}

On {\tt micmac\_data/ExempleDoc/} the directory {\tt MiniCuxha} contains
$48$ images of the St-Michel de Cuxa's abbey \footnote{they are low resolution images
to limit the  downloading time}. This data set illustrates how to
do a bundle adjustment with ground control points.

\begin{figure}[H]
\begin{center}
\includegraphics[width=160mm]{FIGS/Cuxa/Planche.jpg}
\caption{Image of Saint-Michel de Cuxa's data set }
\end{center}
\label{FIG:Glob:Cuxa}
\end{figure}

These images have been taken with an helicopter drone at an approximate height of 100 meters, in a typical aerial photogrammetric setup.

\vspace{\baselineskip}
The "standard pipeline" to do a bundle adjustment with ground control points with {\tt MicMac} is:
\begin{itemize}
\item compute images relative orientations, with {\tt Tapioca} and {\tt Tapas};
\item transform GCP coordinates into a local euclidean coordinate system, with {\tt GCPConvert};
\item measure image coordinates for a small set of GCP, with {\tt SaisieAppuisInit};
\item transform image relative orientations into the same local coordinate system, with {\tt GCPBascule};
\item measure image coordinates for all GCP, with {\tt SaisieAppuisPredic};
\item transform image relative orientations into the local coordinate system, with {\tt GCPBascule};
\item run the bundle adjustment, with {\tt Campari};
\item transform back relative orientations into an appropriate coordinate system, with {\tt ChgSysCo};
\item compute a rectified image, with {\tt Tarama};
\item make the matching with {\tt Malt};
\item generate the ortho image with {\tt Tawny};
\end{itemize}

\vspace{\baselineskip}
The file {\tt CmdAbbey.txt} contains all the commands needed to process these data.


%-------------------------------------------------------------------

\subsection{Computing tie points and relative orientations}

    %  -  -  -  -  -  -  -  -  -  -  -  -

\subsubsection{Tie points}

As usual, we want to compute matches between all pairs of calibration data set. This is done by:

\begin{verbatim}
Tapioca MulScale "Abbey-IMG_.*.jpg" 200 800
\end{verbatim}

    %  -  -  -  -  -  -  -  -  -  -  -  -

\subsubsection{Relative orientation}

Then we want to make a first calibration with a subset of the whole data, and
use this calibration as an initial value to the global relative orientation of all images. This is done by:

\begin{verbatim}
Tapas RadialBasic "Abbey-IMG_(0248|0247|0249|0238|0239|0240).jpg" Out=Calib
Tapas RadialBasic "Abbey-.*.jpg" InCal=Calib Out=All-Rel
\end{verbatim}

We can verify that relative orientation was successful by checking the ``Residu Liaison Moyens'' (root mean square error) value that should be around 0.5 pixel.
We can also check visually the result of orientation running {\tt AperiCloud}, described in \ref{APERICLOUD}:

\begin{verbatim}
AperiCloud  "Abbey-IMG_[0-9]*.jpg" All-Rel RGB=0
\end{verbatim}

This will generate the AperiCloud.ply file containing tie points and cameras locations. We can see that cameras are on the same plane, and that the relative orientations match the flight
plan:

\begin{figure}[H]
\begin{center}
\includegraphics[width=180pt]{FIGS/Cuxa/AperiCloud.jpg}
\includegraphics[width=208pt]{FIGS/Cuxa/Aero.jpg}
\caption{Result of relative orientation, computed with {\tt AperiCloud}, perspective and top view.}
\end{center}
\end{figure}

%-------------------------------------------------------------------

\subsection{GCP transforms}

    %  -  -  -  -  -  -  -  -  -  -  -  -

\subsubsection{Ground control point coordinates conversion}

In this use case, we have got ground control points expressed in {\tt WGS84} system. We need to convert them into a local euclidean coordinate system. The important thing is that the local system is euclidean, because all the {\tt MicMac} tools
need this assumption to solve equations. Most of the cartographic coordinate systems are not euclidean systems, so we define a local tangent system, defined around a 3D point and its tangent plane, that will lead to a geometry compliant with {\tt MicMac}'s one.
This is done with the {\tt GCPConvert} tool (detailed in \ref{GCPConvert}):

\begin{verbatim}
GCPConvert "#F=N_X_Y_Z_I" F120601.txt ChSys=DegreeWGS84@SysCoRTL.xml Out=AppRTL.xml
\end{verbatim}

\subsubsection{Ground control point image coordinates input}

To add image coordinates measures, we can use the {\tt SaisieAppuisInit} interface in Linux (detailed in \ref{SaisieAppuisInit}):

\begin{verbatim}
SaisieAppuisInit  "Abbey-IMG_0211.jpg"  All-Rel  NamePointInit.txt  MesureInit.xml
\end{verbatim}

This will create two {\tt Xml} files {\tt MesureInit-S2D.xml} and {\tt MesureInit-S3D.xml}, which respectively contain images coordinates and corresponding 3D coordinates, computed by spatial resection.

\subsubsection{Bascule}

Now we can transform images relative orientations, as computed with Tapas, expressed in an arbitrary coordinate system,
into the local euclidean coordinate system, using 2D images coordinates measures and 3D corresponding ground control points.

\begin{verbatim}
GCPBascule "Abbey-.*jpg" All-Rel  RTL-Init  AppRTL.xml  MesureInit-S2D.xml
\end{verbatim}

Once the images relative orientations have been transformed back in local euclidean coordinate system, one can verify that Z coordinates for the whole data set is nearly constant, which corresponds to the data acquisition setup.

\vspace{\baselineskip}
Possible error: "{\tt Not enough samples (Min 3) in cRansacBasculementRigide}". It means that there is not enough points to compute a Bascule transform. You should add more points with {\tt SaisieAppuisInit}:
at least 3 GCP whose projection are known in at least 2 images are needed.

\subsubsection{Adding points with predictive interface {\tt SaisieAppuisPredic}}

When the global transform between ground control points and image relative orientations is known, we can switch to the predictive interface {\tt SaisieAppuisPredic} which will display the remaining ground control points, loaded from the {\tt Xml} file {\tt AppRTL.xml}.
You need to adjust points image location and validate them.

\begin{verbatim}
SaisieAppuisPredic  "Abbey-.*jpg" RTL-Init AppRTL.xml  MesureFinale.xml
\end{verbatim}

\subsubsection{Bascule}

Again we can transform images relative orientations, this time with a more substantial number of images measures, which will give a better transform.
\begin{verbatim}
GCPBascule "Abbey.*jpg" All-Rel  RTL-Bascule AppRTL.xml MesureFinale-S2D.xml
\end{verbatim}

%-------------------------------------------------------------------

\subsection{Bundle adjustment with ground control points}

\label{Bundle:CAMPARI}

Now we can run a constrained bundle adjustment combining ground control points and tie points, with the {\tt Campari} command, described in \ref{CAMPARI}.

\begin{verbatim}
Campari "Abbey.*.jpg"  RTL-Bascule RTL-Compense GCP=[AppRTL.xml,0.1,MesureFinale-S2D.xml,0.5]
\end{verbatim}

%-------------------------------------------------------------------

\subsection{Post-processing}

\subsubsection{Coordinate system backward transform}

Then one can transform coordinates from the local euclidean coordinate system to a geographic coordinate system, and compute ortho-images which can be superimposed on vectorial maps (and \textit{vice versa}).
For example, if we want to transform our data into the sinusoidal projection, for which we have got a file {\tt SysCoSinus90W.xml} storing the transformation parameters, the command is:

\begin{verbatim}
ChgSysCo  "Abbey.*.jpg" RTL-Compense SysCoRTL.xml@SysCoSinus90W.xml Sin90

Tarama  "Abbey.*.jpg" Sin90

Malt Ortho  "Abbey.*.jpg" Sin90 SzW=1 AffineLast=false DefCor=0.0

Tawny Ortho-MEC-Malt/
\end{verbatim}

\begin{figure}[H]
\begin{center}
\includegraphics[width=150mm]{FIGS/Cuxa/Sinus-Ortho-Eg-Test-Redr.jpg}
\caption{Image rectification in sinusoidal projection, with {\tt Tarama}}
\end{center}
\end{figure}

%\begin{figure}[H]
%\begin{center}
%\includegraphics[width=150mm]{FIGS/Cuxa/SinusShade.jpg}
%\caption{Shading in sinusoidal projection, with {\tt GrShade}}
%\end{center}
%\end{figure}

The result is ugly, but if we have a look to the global earth mapping with sinusoidal projection, it is obvious that we cannot have a good representation at the European longitude with the sinusoidal projection.

\begin{figure}[H]
\begin{center}
\includegraphics[width=182pt]{FIGS/Cuxa/Sinus90.jpg}
\caption{Sinusoidal projection, with Central Meridian $90\,^{\circ}$W}
\end{center}
\end{figure}

What we expect would be more like the result of a projection in Lambert93 coordinate system:

\begin{verbatim}
ChgSysCo  "Abbey.*.jpg" RTL-Compense SysCoRTL.xml@Lambert93 L93

Tarama  "Abbey.*.jpg" L93

Malt Ortho  "Abbey.*.jpg" L93 SzW=1 AffineLast=false DefCor=0.0

Tawny Ortho-MEC-Malt/
\end{verbatim}

\begin{figure}[H]
\begin{center}
\includegraphics[width=160mm]{FIGS/Cuxa/L93-Ortho-Eg-Test-Redr.jpg}
\caption{Image rectification in Lambert93 projection, with {\tt Tawny}}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=160mm]{FIGS/Cuxa/L93-Shade.jpg}
\caption{Shading in Lambert93 projection, with {\tt GrShade}}
\end{center}
\end{figure}

%-------------------------------------------------------------------
\section{The Grand-Leez dataset}
%-------------------------------------------------------------------

\subsection{Dataset description}\label{Grand-Leez:DataSet}

The directory {\tt UASGrandLeez/} in {\tt micmac\_data/ExempleDoc/}, contains UAS\footnote{Unmanned Aerial System or {\tt drone}} imagery which are used to illustrate a complete workflow devoted to the the production of a canopy surface model. 
The aerial survey was performed by the lab of Forest and Nature Management\footnote{\url{http://www.gembloux.ulg.ac.be/gestion-des-ressources-forestieres-et-des-milieux-naturels/}} of the University of Liege (Belgium). 
The image block is made up of 200 low-oblique vantage jpeg images, acquired with a Ricoh GRIII (10 Mpixels, focal length of 28 mm 35 equivalent). 
The flight was performed with a Gatewing X100 platform.
The inertial measurement unit provides GPS position and attitude (omega, phi, kappa) of the UAS for each image frame (stored in {\tt GPS\_WPK\_Grand-Leez.csv} file). 
In order to reduce the size of this dataset, raw images were resampled to 800 pixels width. 
The processing of these images can however take a few hours. 
The file {\tt  Documentation/FIGS/UASGrandLeez/Cmd\_UAS\_Grand-Leez.txt} contains all the command lines related to this processing workflow.

First, let's take a look at the images. 
A convenient tool to visualize multiple images in a panel is the {\tt PanelIm} tool which was used to produce figure \ref{FIG:panel-GL} and other image panels in this manual:

\begin{figure}[H]
\centering
\includegraphics[height=0.5\linewidth]{FIGS/UASGrandLeez/PanelGL.JPG}
\caption{The Grand-Leez dataset}
\label{FIG:panel-GL}
\end{figure}

\begin{verbatim}
mm3d PanelIm ./ "R00405[0-5][0:2:4:6:8].JPG" Scale=3
\end{verbatim}

In this example, we deal with direct georeferencing, which consist of using camera positions (or camera center) to georeference the photogrammetric model. 
At first, the tool {\tt OriConvert} (section \ref{OriConvert})  is used to convert telemetry data into {\tt MicMac} format. 
Telemetry data aren't exclusively used for georeferencing, but also to determine potential image pairs.
The list of image pairs is then used for the computation of tie points ({\tt Tapioca File \dots}). 
In addition, embedded GPS data are used in a constrained bundle block adjustment in order to avoid non-linear distortions which can hinder photogrammetric measurements.

The pipeline presented here to process UAS imagery with embedded GPS data with {\tt MicMac} is organized as follows:
\vspace{\baselineskip}
\begin{enumerate}
 \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
\item Transform initial external orientation file (embedded GPS data) into the {\tt MicMac} format and generate an image pairs file with {\tt OriConvert}. 
In addition, latitude and longitude GPS information are projected in the Belgian Lambert 72 coordinate system;
\item Compute image tie points with {\tt Tapioca File};
\item Initialize the image block orientation with {\tt Martini};
\item Determine image relative orientation, with {\tt Tapas};
\item Transform image relative orientation into absolute orientation, e.g. performing direct georeferencing, with {\tt CenterBascule};
\item Improve the aerotriangulated model by adding GPS information in the bundle block adjustment, with {\tt Campari};
\end{enumerate}
\vspace{-0.8\topsep}
It results in the image orientation ({\tt Ori-BL72-Campari}), which is used to perform the image dense matching and subsequently the image orthorectification and mosaicking.
The canopy surface is characterized by many abrupt vertical changes, which are difficult to model by image matching. 
The dense matching is performed in \textit{image geometry} with the \textit{Per Image Matchings} tool {\tt PIMs}. 
Thus, one depth map is computed for each image. 
These depth maps are then georeferenced and merged in one single digital surface model covering the entire area.
The canopy surface model is then used of orthorectification and individual orthoimages are then mosaicked.
The remaining of the workflow is thus as follows;
\vspace{-0.8\topsep}
\begin{enumerate}\addtocounter{enumi}{6}
 \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
\item Compute depth map for each image with \textit{Per Image Matching} Tools ({\tt PIMs});
\item Merge individual depth maps in a global Digital Surface Model  and compute orthoimage with {\tt PIMs2Mnt};
\item Merge individual orthoimages in an orthophotomosaic with {\tt Tawny}.
\end{enumerate}
\vspace{-0.8\topsep}

\subsection{Computing tie points and absolute orientation}

Figure \ref{FIG:workflowGLOri} illustrates the determination of the orientation for the image block.
The final orientation database which is used for the dense matching process and for orthophoto generation is the folder \textit{Ori-BL72-Campari}.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{FIGS/UASGrandLeez/workflowGLOri.jpg}
\caption{The processing chain for computing the image orientation (\textit{Ori-BL72-Campari}). Processing steps are numbered in red.}
\label{FIG:workflowGLOri}
\end{figure}

\subsubsection{Conversion of GPS data in {\tt MicMac} format}

\begin{verbatim}
mm3d OriConvert OriTxtInFile GPS_WPK_Grand-Leez.csv GPS-BL72  MTD1=1\
       ChSys=DegreeWGS84@SysCoBL72_EPSG31370.xml  NameCple=FileImagePairs.xml 
\end{verbatim}
Note that {\tt MicMac} uses the proj4 library to change the coordinate systems. 
The Belgian Lambert 72 coordinate system is defined using its "proj4 code" written in an xml file (see {\tt SysCoBL72\_EPSG31370.xml})

\subsubsection{Tie points}
The file {\tt FileImagePairs.xml} is used for computing tie points with {\tt Tapioca}.

\begin{verbatim}
Tapioca File ``FileImagePairs.xml'' -1
\end{verbatim}

Tie points are used as observations in the bundle adjustment ({\tt Tapas} and {\tt Campari}) to determine the element of image orientation (external orientation and camera calibration). 

\subsubsection{Relative orientation}

Initialization of the orientation for a large image block (hundreds of image) can be carried out with the {\tt Martini} tool:

\begin{verbatim}
mm3d Martini "R.*.JPG"
AperiCloud "R.*.JPG" Martini Out=Martini-cam.ply WithPoints=0
\end{verbatim}
As {\tt Martini} does not account for any radial distortion of the lens, the visual inspection of the image orientation with {\tt AperiCloud} shows large non-linear distortions.
Initialization of the image orientation can also be performed successfully directly with {Tapas}, but for a large image block, the use of {\tt Martini} is faster.
The complete dataset is then aligned in a relative orientation {\tt Rel} with the following command line:

\begin{verbatim}
Tapas RadialBasic "R.*.JPG" Out=Rel InOri=Martini
\end{verbatim}

\subsubsection{Georeferencing}

The center database {\tt Ori-GPS-BL72} is employed to georeference the aerotriangulated model with { \tt CenterBascule}:

\begin{verbatim}
CenterBascule "R.*.JPG" Rel GPS-BL72 BL72
\end{verbatim}

\subsubsection{Bundle adjustment with embedded GPS data}

Adding GPS information in the bundle adjustment has a positive impact on the refinement of the camera orientation, in particular on the camera calibration.
\begin{verbatim}
Campari "R.*.JPG" BL72 BL72-Campari EmGPS=[GPS-BL72,2] FocFree=1 PPFree=1
\end{verbatim}

\subsection{Dense matching and orthorectification}

The digital surface model of the canopy is created with {\tt PIMs} and {\tt PIMs2Mnt}.

\begin{verbatim}
mm3d PIMs Forest "R00.*.JPG" BL72-Campari  ZoomF=2
\end{verbatim}

The mode {\tt Forest} of the {\tt PIMs} tool is appropriate for aerial images of forested zones. 
In this mode, a dense matching is performed independently for every pair of successive images.
In the terminal, a message display the pairs that will be used for stereo image matching (in epipolar geometry):
\begin{verbatim}
Adding the following image pair: R0040571.JPG and R0040570.JPG 
Adding the following image pair: R0040572.JPG and R0040571.JPG 
Adding the following image pair: R0040573.JPG and R0040572.JPG 
...
\end{verbatim}

Dense matching is time consuming and generates a lot of intermediate results.
Figure \ref{FIG:pimsGL} illustrates the functioning of the  \textit{Per Image Matchings} approach.

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{FIGS/UASGrandLeez/PIMsGL.jpg}
\caption{Simplified representation of the functioning of the \textit{Per Image Matchings} approach implemented in the {\tt PIMs Forest} tool.
Image dense matching is performed for a list of image pairs, resulting in one (or more) depth map per image.
These depth maps are georeferenced and merged together with the tools {\tt PIMs2Mnt}. }
\label{FIG:pimsGL}
\end{figure}

Stereo depth maps are merged together with {\tt PIM2Mnt}. 
Subsequently, orthorectification is performed for each image and orthoimages are stored in the directory { \tt PIMs-ORTHO/}.

\begin{verbatim}
mm3d PIMs2Mnt Forest DoOrtho=1
\end{verbatim}

The global digital surface model resulting from the merging of every single depth map is the raster file named {\tt PIMs-TmpBasc/PIMs-Merged\_Prof.tif}.
It can be visualized and analysed in any GIS software. 
Eventually, orthoimages are mosaicked together with {\tt Tawny}.
Because the radiometry of the different images are quite similar (no important illumination changes during the image acquisition), no radiometric equalization is performed ({\tt RadiomEgal=0}).

\begin{verbatim}
Tawny PIMs-ORTHO/ RadiomEgal=0 Out=Orthophotomosaic.tif
\end{verbatim}

The digital surface model and the orthophotomosaic can be combined in a colored 3D point cloud with  {\tt Nuage2Ply } (see figure \ref{fig:GL_nuage}).

\begin{verbatim}

# export the dense point cloud and colorize it with Nuage2Ply:
Nuage2Ply "PIMs-TmpBasc/PIMs-Merged.xml" Scale=1 /
	Attr="PIMs-Ortho/Orthophotomosaic.tif" RatioAttrCarte=2 Out=CanopySurfaceModel.ply
       
# Optionally, if meshlab is installed:
meshlab CanopySurfaceModel.ply
\end{verbatim}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{FIGS/UASGrandLeez/GL_ori.jpg}
\includegraphics[width=0.49\linewidth]{FIGS/UASGrandLeez/GL_zoomDSM.jpeg}
\includegraphics[width=0.49\linewidth]{FIGS/UASGrandLeez/GL_zoomOrtho.jpeg}
\includegraphics[width=\linewidth]{FIGS/UASGrandLeez/GL_denseCloud.jpg}
\caption{Illustration of the different results for the Grand-Leez dataset. 
Top: the orientation (camera poses and tie points). 
Middle left: zoom-in on the canopy relief. 
Middle rigth: zoom-in on the orthophotomosaic.
Bottom: the colored dense 3D point cloud.}
\label{fig:GL_nuage}
\end{figure}


%-------------------------------------------------------------------
\section{GoPro Video data-set}
%-------------------------------------------------------------------

\subsection{Description of the data set}\label{GoProVideo:DataSet}

The caracteristics of the acquisition are :

\begin{itemize}
   \item Data is a video {\tt LM.mp4};
   \item This video was acquired with a GoPro camera mounted on a paraglider;
   \item The target is a cliff as illustrated on figure ~\ref{fig:GoProIm1};
   \item Part of the images contains sea with flooding wave;
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{FIGS/GoProVideo/Im1Ok.jpg}
\caption{First image of video  {\tt LM.mp4}}
\label{fig:GoProIm1}
\end{figure}


The issue we have to deal with are the following :

\begin{itemize}
   \item MicMac can process still images and not video;
   \item If we extract all the images, we will have too much redundant data, as can be seen
         on figure~\ref{fig:GoProCloseWave} with two consecutive images in superposition;
   \item The waves generate a lot of tie points (see figure~\ref{fig:GoProSIFT}) , which will be 
         a problem for photogrammetry as  they are 
         obviously not motionless relatively to the cliff;
          
   \item Currently with video, a lot of image are blurred (although it's not so much the case here ...);
   \item  There is no meta data embedded with video (at least, they disappear with the tool used to extract
          still images);
   \item  With this camera, there is a rolling shutter, so potentially each images has its own deformation;
\end{itemize}


\begin{figure}
\centering
\includegraphics[width=0.80\linewidth]{FIGS/GoProVideo/Proches.jpg}
\caption{Two consecutive images of the video in superposition}
\label{fig:GoProCloseWave}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=0.90\linewidth]{FIGS/GoProVideo/SIFT.jpg}
\caption{Tie points from two extracted images}
\label{fig:GoProSIFT}
\end{figure}


\subsection{The commands}\label{GoProVideo:Commands}

The file {\tt Cmd.txt} in {\tt Documentation/FIGS/GoProVideo} contains the commands that have been used. They are :

\begin{verbatim}
# Develop all  images
ffmpeg -i LM.mp4  Im_0000_%5d_Ok.png

# Add missing xif
mm3d SetExif .*png F35=20 F=4.52 Cam=GoProVideoLM

# Select  approximatively 3 image / sec , preferring the sharpest one
mm3d DIV Im_0000_.*png Rate=3

#  Put the unselected images in basket
mkdir POUB
mv *Nl.png POUB/

#  Tie points adapted to  linear acquisition
Tapioca Line .*png 1000 10

# Compute a initial calibration; would not be necessary if we had already used this camera
mm3d Tapas  FishEyeBasic Im_0000_000.*png Out=Calib

#  Orient all the images
mm3d Tapas  FishEyeBasic Im_0000_.*png InCal=Calib Out=All0

# Generate a ply to visualize the scene
AperiCloud  .*png Ori-All0/

# Input a 2D mask that removes the sea
mm3d SaisieMasqQT  AperiCloud_All0.ply

#Filter the homologous point
mm3d HomolFilterMasq .*png OriMasq3D=Ori-All0/

# rename homologous points, the filtered one will be seen as the default
mv Homol HomolInit
mv HomolMasqFiltered/ Homol


# Compute orientation without the sea
Tapas   FishEyeBasic .*png InOri=Ori-All0/ Out=All1

# Free parameters
Campari  .*png  All1 All2 CPI1=1 FocFree=1 PPFree=1 AffineFree=1

# Generate the point cloud

mm3d C3DC BigMac .*png Ori-All2/ Tuning=0 Masq3D=AperiCloud_All2.ply ZoomF=1

\end{verbatim}



\subsection{Some comments}\label{GoProVideo:Comments}


\subsubsection{Developing still images with  {\tt ffmpeg}}

The software  {\tt ffmpeg} is a free open source package, we use it to extract the still images from video. Note :

\begin{itemize}
   \item We ask to extract \emph{all} the images, because we want to do  \emph{a posteriori} our own selection 
         of non-blurry images;
   \item To do this selection it is a requirement that the images use {\tt ffmpeg}  with the naming
          {\tt Im\_0000\_\%5d\_Ok.png}  (well the tool is still in very prototype state);

\end{itemize}


\subsubsection{Adding missing xif with {\tt SetExif}}

As there is no {\tt exif} information in the data set, we  add it to avoid the use of {\tt MicMac-LocalChantierDescripteur.xml}.
Note that is important to do it at the very beginning of the process, before using any other {\tt MicMac} tool, because after the xif 
will memorized in the {\tt Tmp-MM-Dir/.*xml} files


\subsubsection{Selecting sharpest images with  {\tt DIV}}

The {\tt DIV} command, makes selection of video images.
{\tt mm3d DIV Im\_0000\_.*png Rate=3} means : select approximately $3$ images per second 
(in fact one image out of $8$, assuming an initial rate $24$ images per second).  As some image have to be deleted,
this rate is only an approximation.

It the image is selected, its name is unchanged, while "deleted" images are renamed by replacing {\tt Ok} by {\tt Nl}.
As we don't want to use the deleted images, we put them in a "trash can" with the two lines 
{\tt mkdir POUB} and {\tt mv *Nl.png POUB/}.


\subsubsection{Standard orientation}

The three next line are quite standard MicMac processing :

\begin{itemize}
    \item {\tt  Tapioca Line .*png 1000 10} , compute tie point with command adapted to a linear acquisition;
    \item {\tt  mm3d Tapas  FishEyeBasic Im\_0000\_000.*png Out=Calib}, compute a first value of calibration , we
         use a fish-eye model adapted to this GoPro camera;
    \item {\tt  mm3d Tapas  FishEyeBasic Im\_0000\_.*png InCal=Calib Out=All0}, orient all the images, starting from
         the calibration
    \item {\tt  AperiCloud  .*png Ori-All0/} generate a ply file to visualize the scene and position of camera (see~\ref{fig:GoProOri0});

\end{itemize}

\begin{figure}
\centering
\includegraphics[width=0.80\linewidth]{FIGS/GoProVideo/Aperi000.jpg}
\caption{Orientation of images}
\label{fig:GoProOri0}
\end{figure}


\subsubsection{Seizing the waves}

With such acquisition, the best option to seize the location of the wave, is to seize in 3D. The other alternative, 
seize them in each images, would be much more time consuming. For this we can use the {\tt SaisieMasqQT} command,
see~\ref{Doc:SaisieMasqQT}.


\begin{figure}
\centering
\includegraphics[width=0.80\linewidth]{FIGS/GoProVideo/Masq3D.jpg}
\caption{Seizing 3D masq  of the cliff}
\label{fig:GoProOri0}
\end{figure}

\subsubsection{Filtering homologous points}

We can now use the  {\tt HomolFilterMasq} command to select the tie points that are inside the $3$d masq.
We use the {\tt OriMasq3D} option to indicate the orientation (necessary to compute by ray intersection the $3$d point
associated to each tie point). By default, it assume that the mask has been seized on a {\tt AperiCloud} result, and
the default name of the $3$d mask is  here {\tt AperiCloud\_All2\_polyg3d.xml} .


\begin{figure}
\centering
\includegraphics[width=0.90\linewidth]{FIGS/GoProVideo/SIFT2.jpg}
\caption{Tie points from  two extracted images after selection by $3$d masq}
\label{fig:GoProSIFT2}
\end{figure}

We have the to rename the homologous folder because by default all the MicMac command search the tie points 
in the folder {\tt Homol} :

\begin{verbatim}
mv Homol HomolInit
mv HomolMasqFiltered/ Homol
\end{verbatim}

\subsubsection{Final orientation}

Then we have two command to run to have the final orientation :


\begin{itemize}
   \item {\tt Tapas   FishEyeBasic .*png InOri=Ori-All0/ Out=All1} , here we run {\tt Tapas} taking into account
         the set of tie points without the sea;

   \item {\tt Campari  .*png  All1 All2 CPI1=1 FocFree=1 PPFree=1 AffineFree=1} , here we run {\tt Campari} with the option
         that select one internal calibration by images, we free the $0$ and $1$ degree parameter to take into account the
          rolling shutter (is it sufficient ? This is another story \dots).
\end{itemize}

And finally we can use the {\tt C3DC} command to generate a point cloud, a snapshot is presented on figure {\tt fig:GoProPlyFin}.

\begin{verbatim}
mm3d C3DC BigMac .*png Ori-All2/ Tuning=0 Masq3D=AperiCloud_All2.ply ZoomF=1
\end{verbatim}

\begin{figure}
\centering
\includegraphics[width=0.90\linewidth]{FIGS/GoProVideo/PLY-Climb00.jpg}
\caption{Tie points from  two extracted images after selection by $3$d masq}
\label{fig:GoProPlyFin}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The satellite data set}\label{sec:usecase:satel}
%
\subsection{Description of the data}
%
A Pleiades tristereo is processed in the following. The images are part of a sample dataset disseminated by the Airbus Defence and Space and can be downloaded from http://www.geo-airbusds.com/en/23-sample-imagery 
\subsection{From 2D images to 3D objects -- the processing commands}
%
Unless you work with MicMac and the Kakadu license, the orignal JPEG2000 images must be  converted to tiff. The otb library\footnote{https://www.orfeo-toolbox.org/} allows for the conversion using the command below: 
\begin{verbatim}
otbcli_Convert -in image.jp2 -out image.tif uint16
\end{verbatim}
%
The tie points can now be extracted from the images:
\begin{verbatim}
mm3d Tapioca All .*.tif 10000  
\end{verbatim}
%
Next, as mentioned in Section~\ref{sec:rpcBundle}, the input files with rational polynomial coefficients ought to be converted to a MicMac readable format, and the processing coordinate system defined:
\begin{verbatim}
mm3d Convert2GenBundle IMG_PHR1A_P_201202250025329_SEN_PRG_FC_5110-001_R1C1.tif
RPC_PHR1A_P_201202250025329_SEN_PRG_FC_5110-001.XML RPC-deg1 ChSys=WGS84toUTM.xml Degre=1
mm3d Convert2GenBundle IMG_PHR1A_P_201202250025599_SEN_PRG_FC_5108-001_R1C1.tif
RPC_PHR1A_P_201202250025599_SEN_PRG_FC_5108-001.XML RPC-deg1 ChSys=WGS84toUTM.xml Degre=1
mm3d Convert2GenBundle IMG_PHR1A_P_201202250026276_SEN_PRG_FC_5109-001_R1C1.tif
RPC_PHR1A_P_201202250026276_SEN_PRG_FC_5109-001.XML RPC-deg1 ChSys=WGS84toUTM.xml Degre=1
\end{verbatim}
%
where the content of the coordinate system file renders:
\begin{verbatim}
<SystemeCoord>
  <BSC>
     <TypeCoord>eTC_Proj4</TypeCoord>
     <AuxStr>+proj=utm +zone=55 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs</AuxStr>
  </BSC>
</SystemeCoord> 
\end{verbatim}
%
Given the extracted tie points, the RPC bundle adjustment can proceed with the simplified tool {\tt Campari} (see Subsection~\ref{CAMPARI}):
\begin{verbatim}
mm3d Campari .*.tif RPC-deg1 RPC-deg1_adj
\end{verbatim}
%
Provided the results deliver satisfying residuals (in the presented case reflecting only the reprojection errors of the tie points, but more generally also determining the adherence of the data to some control information), the dense matching can be carried out. Nevertheless, it is worthwhile to verify the refined orientation between pairs of images using the {\tt mm3d MMTestOrient} (see Subsection~\ref{CheckOri}):
\begin{verbatim}
mm3d MMTestOrient IMG_PHR1A_P_201202250025329_SEN_PRG_FC_5110-001_R1C1.tif 
IMG_PHR1A_P_201202250025599_SEN_PRG_FC_5108-001_R1C1.tif Ori-RPC-deg1_adj GB=1 ZMoy=0 ZInc=500
\end{verbatim}
%
The DSM generation is handled, again, by the simplified tool {\tt Malt} (see Subsection~\ref{subsec:Malt}): 
\begin{verbatim}
mm3d Malt UrbanMNE .*.tif Ori-RPC-deg1_adj ZMoy=0 ZInc=500
\end{verbatim}
%

\subsection{Understanding the bundle adjustment output ({\tt Campari})} 
%
The adjustment result is stored inside the {\texttt{Ori-RPC-deg1\_adj}} directory. Understanding the bundle adjustment message printed to the screen (and additionally stored inside a {\tt Residus.xml} file) is already explained in subsection~\ref{subsec:Apero:msg}. The output directory contains files with the original RPCs (all files with the prefix {\tt UnCorExtern-}), and the corresponding files with adjusted orientation parameters (all files with the prefix {\tt GB-}). The {\tt GB-} files contain:
\begin{itemize}
\item {\tt NameCamSsCor}, the filepath to the original RPCs;
\item {\tt NameIma}, the name of the image that the file corresponds to;
\item {\tt SysCible}, the definition of the coordinate system used in the processing (proj4 format);
\item {\tt DegreTot}, the degree of the adjustable 2D polynomial correction function;
\item {\tt Center}, the polynomial's normalizing shift (in pixels);
\item {\tt Ampl}, the polynomial's normalizing amplitude;
\item {\tt CorX}, the polynomial's normalized x-coefficients;
\item {\tt CorY}, the polynomial's normalized y-coefficients;
\item {\tt Monomes}, three values corresponding to respective polynomial terms (e.g. \texttt{<Monomes>-0.94 0 1</Monomes>} interprets as $-0.94 \cdot x^0 \cdot y^1 $). 
\end{itemize}
The avoid numerical instabilities of the polynomial functions, the {\tt Center} and {\tt Ampl} parameters normalize the image space such that all observations are contained within the range $<-1,1>$. The user can visualize the correction polynomial functions with 
\begin{verbatim}
mm3d SateLib SATD2D Ori-RPC-deg1_adj/GB-Orientation-
                    IMG_PHR1A_P_201202250025329_SEN_PRG_FC_5110-001_R1C1.tif.xml
\end{verbatim}
%
The tool produces images of displacements separately in x, y and combined xy directions (see Fig.~\ref{fig:satPoly2d}), and prints to the screen the minimum/maximum values in pixels:
\begin{verbatim}
displacement in x:  GMin,Gax -0.96187676315564 -0.919344454426481
displacement in y:  GMin,Gax -0.542404322159884 0.234261700467604
displacement in xy:  GMin,Gax 0.919404732429707 1.06767206091774
\end{verbatim}
%   
\begin{figure}[h!]
\centering
\includegraphics[width=0.95\linewidth]{FIGS/Satellites/SATD2D.png}
\caption{Displacements in image space caused by the correcting polynomial functions in image \texttt{IMG\_PHR1A\_P\_201202250025329\_SEN\_PRG\_FC\_5110-001\_R1C1.tif}. Displacement magnitude (a) along the x-coordinate, (b) along the y-coordinate, (c) combined along both coordinate directions.}
\label{fig:satPoly2d}
\end{figure}
%
\subsection{Understanding the bundle adjustment validation output ({\tt MMTestOrient})}
% 
The output of the {\tt MMTestOrient} tool described in Section~\ref{sec:MMTestOri} is shown in Fig.~\ref{fig:satMMTestOri}. Using the tool {\tt mm3d StatIm}, some basic image statistics can be obtained allowing the interpretation of the outcome:
\begin{verbatim}
mm3d StatIm GeoI-Px/Px2_Num16_DeZoom2_Geom-Im.tif [1000,1000] Sz=[8000,4000]
\end{verbatim}
%
The command above calculates the mean, the standard deviation, as well as min/max parallax values over the bounding box anchored at [1000,1000], of size [8000,4000]. Because the input parallax image is at the \texttt{DeZoom=2}, rather than the full resolution, all values must be multiplied by two. The image statistics over the selected bounding box in pixels are then:
\begin{verbatim}
ZMoy=0.064 ; Sigma=0.122
ZMinMax=[-2.70 , 2.03]
\end{verbatim}
%   
The two most relevant statistics are: the mean transverse parallax which is very close to zero, and the sigma equal to $\approx 0.1$ pixel. The min/max values are relief-related and occur in places of low correlation, e.g. on vegetation, water surfaces, or in places of shadows and occlusions. The magnitude of systematic pattern visible in Fig.~\ref{fig:satMMTestOri} remains at the level of the sigma value, hence well below the adjustment precision ($~0.6$ pixel). The user is encouraged to use \texttt{mm3d Vino} tool to display very big image files.
%
\begin{figure}[h!]
\centering
\includegraphics[width=0.95\linewidth]{FIGS/Satellites/IMG_Px1_Px2_Num16.png}
\caption{(a) A satellite image, (b) the epipolar parallax (\texttt{Px1\_Num16\_DeZoom2\_Geom-Im.tif}), (c) the transverse parallax (\texttt{Px2\_Num16\_DeZoom2\_Geom-Im.tif}).}
\label{fig:satMMTestOri}
\end{figure}
