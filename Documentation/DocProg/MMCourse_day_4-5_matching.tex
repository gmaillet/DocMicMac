\selectlanguage{english}

\section{C++ course under MicMac's library : Elise}

This section contains the note taken by Ewelina Rupnik that I integrated in this chapter.

\subsection{Introduction and generalities}
A \verb!C++! course was organized at ENSG (The National School of Geographic Sciences). The purpose of this course was to learn how to add own equations in the bundle adjustment (Apero), as well as how to perform dense matching in epipolar geometry (MicMac). Additionally, a brief introduction to creation of own image filters within the Elise library was given.\newline
This section provides the documentation of the 'matching' part of the course and is structured into three subsections. The subsection are as follows
\begin{itemize}
  \item[*] overview of the new classes and interfacing with \emph{mm3d} in subsection \ref{subsection:class},
  \item[*] preprocessing (epipolar images; 3D mask; multiscale) in subsection \ref{subsection:preproc},
  \item[*] the matching (with and without regularization) in subsection \ref{subsection:match},
\end{itemize}

The dataset used to test the code was a pair of terrestrial images. The images and its corresponding orientation files can be found in mercurial repository in the directory \emph{YYYYY-EXO-XXXXXX}.

\subsection{Overview of the new classes and interfacing with \emph{mm3d} }\label{subsection:class}
Classes created to manipulate the images during matching
\begin{itemize}
  \item[*] \textbf{cOneImTDEpip} to store an image, the camera data, plus generate names and commands for downscaled images,
  \item[*] \textbf{cLoadedImTDEpip} to store the image pair, parallax image and to do matching (in short)
  \item[*] \textbf{cAppliTDEpip} to manage the entire pipeline of the matching as well as to store the user's input\newline
\end{itemize}

%cLoaedImTDEpip - constructor gets a pointer to the cOneImTDEpip image and start zoom;
%this constructor loads the appropriate image (at a desired scale)
%this is happening inside cAppliTDEpip::DoMatchOneScale
%+++++
%(1) cAppliTDEpip anAppli(argc,argv)
%        the constructor: loads all the settings (working dir, mask)
%	                 creates new cOneImTDEpip for each img of the pair
%			 creates downscaled images (and saves them to drive)
%                         does DoMatchOneScale(mZoomDeb,2);
%                              instiantiates cLoaedImTDEpip for each image of the pair, at the current zoom level (aLIm1, aLIm2)
%			      computes the parallax aLIm1.ComputePx(aLIm2,round_up(mIntPx/aZoom) ,aSzW);
%                                                     creates images for the Inf Sup envelopes
%                                                     ComputePx(aIm2,aTEnvInf,aTEnvSup,aSzW);
%						     gfff



\noindent Below are the steps to follow in order to interface the code with the \emph{mm3d} tool
\begin{itemize}
  \item[*] create cTD\_Epip.cpp file to store the code and put it in ../culture3d/src/TpMMPD/

  \item[*] update ../culture3d/src/TpMMPD/Sources.cmake to include the declaration of the file with your code
    \begin{lstlisting}
	  ${TDPPMD_DIR}/cTD_Epip.cpp
       \end{lstlisting}
  \item[*] declare the main function in ../culture3d/include/general/arg\_main.h
       \begin{lstlisting}
	 int TDEpip_main(int argc, char **argv);
       \end{lstlisting}
     \item[*] link the main function with the auxiliary list in \emph{mm3d} (under TestLibAvailableCommands())
	\begin{lstlisting}
	   aRes.push_back(cMMCom("TDEpi",TDEpip_main,"Test  epipolar matcher  "));
	\end{lstlisting}
\end{itemize}

\noindent \emph{TDEpi} is invoked from the terminal with
\begin{lstlisting}
	mm3d TestLib TDEpi
\end{lstlisting}



\subsection{Preprocessing}\label{subsection:preproc}

\subsubsection{Epipolar images} The images are transformed to epipolar geometry by altering their orientations. In epipolar geometry homologous points of the left image lie along lines in the right image. The lines are coincident with the row of the left image and run parallel to the axes of the pixel coordinate system. This way the matching problem is reduced to a 1D search along image rows. Generating epipolar images is done with
\begin{lstlisting}
	mm3d CreateEpip IMGP7032.JPG IMGP7032.JPG RTL-Init Ori-CalPerIm
\end{lstlisting}

\subsubsection{3D mask}
It is possible to restric the volume that will be considered in matching directly in 3D space with the command below
\begin{lstlisting}
mm3d SaisieMasqQT AperiCloud_CalPerIm.ply
\end{lstlisting}

{\tt SaisieMasqQT} tool allows one to select the region of interest with polylines. With the F9 key one switches between selection and manipulation mode. F1 causes the help menu to appear. Two files are created at the output of the above operation. One of the files contains the list of selected 3D points, and the other one holds some transformation parameters.

\subsubsection{Multiscale approach}
Dense image matching is generally performed in a multiscale approach. Starting with low resolution and very rough approximation of the 3D scene, the result is propagated and improved at higher resolutions. Inside the \emph{TDEpi} tool, the downscaling of the image is handled inside the constructor of the \textbf{cAppliTDEpip} class. The function executing the task (\emph{GenerateDownScale}) has two input arguments that are the starting and final zoom (i.e. resolution). As a result, the images at given resolutions are saved on the hard drive of your PC.

\begin{lstlisting}
void cAppliTDEpip::GenerateDownScale(int aZoomBegin,int aZoomEnd)
  {
	  std::list<std::string> aLCom;
	  for (int aZoom = aZoomBegin ; aZoom >= aZoomEnd ; aZoom /=2 )
	  {
		  std::string aCom1 = mIm1->ComCreateImDownScale(aZoom);
		  std::string aCom2 = mIm2->ComCreateImDownScale(aZoom);

		  if (aCom1!="") aLCom.push_back(aCom1);
		  if (aCom2!="") aLCom.push_back(aCom2);

	  }

	  cEl_GPAO::DoComInParal(aLCom);
  }
\end{lstlisting}



\subsection{The matching}\label{subsection:match}
The general workflow of the dense image matching in MicMac (normalized cross correlation (NCC) as the similarity measure) is
\begin{itemize}
  \item create the object Zinf, Zsup,
  \item fill the correlation object Corr(x,y,z),
  \item run optimization (if with regularization)
\end{itemize}

\subsubsection{The similarity measure}
There exist a number of local similarity measures that are commonly used for dense matching. They can be either pixel-based (e.g. Census, Mutual Information) or window-based (e.g. normalized cross correlation (NCC)). The pixel-based features must always be accompanied by a regularization scheme in order to remove the matching ambiguities. Window-based features can be used with and without the regularization. The NCC measure is adopted in the following code.\newline

\noindent In NCC there are five terms that need computation
\begin{itemize}
  \item[(a)] the average intensity of each image,
  \item[(b)] the average of the squared value of the image intensities,
  \item[(c)] the variances of the two windows being examined, and
  \item[(d)] their covariance.\newline
\end{itemize}
\noindent The values of (a) and (b) are computed in the constructor of the \textbf{cLoaedImTDEpip} class. They are computed once and their values are stored inside the class.


\begin{lstlisting}
cLoaedImTDEpip::cLoaedImTDEpip(cOneImTDEpip & aOIE,double aScale,int aSzW) :
  mOIE (aOIE),
  mAppli (aOIE.mAppli),
  mNameIm (aOIE.NameFileDownScale(aScale)),
  mTifIm  (mNameIm.c_str()),
  mSz     (mTifIm.sz()),
  mTIm    (mSz),
  mIm     (mTIm._the_im),
  mTImS1  (mSz),
  mImS1   (mTImS1._the_im),
  mTImS2  (mSz),
  mImS2   (mTImS2._the_im),
  mTPx    (mSz),
  mIPx    (mTPx._the_im),
  mTSc    (mSz),
  mISc    (mTSc._the_im),
  mMasqIn (mSz.x,mSz.y,1),
  mTMIn   (mMasqIn),
  mMasqOut(mSz.x,mSz.y,0),
  mTMOut  (mMasqOut),
  mMaxJumpPax (2),
  mRegul      (0.05)
{
	ELISE_COPY(mIm.all_pts(), mTifIm.in(),mIm.out());

	ELISE_COPY(mMasqIn.border(aSzW),0 ,mMasqIn.out());

	ELISE_COPY
	(

	    mIm.all_pts(),
	    rect_som(mIm.in_proj(),aSzW) / ElSquare(1+2*aSzW),
	    mImS1.out()
	);
	ELISE_COPY
	(
	    mIm.all_pts(),
	    rect_som(Square(mIm.in_proj()),aSzW) / ElSquare(1+2*aSzW),
	    mImS2.out()
	);
}
\end{lstlisting}

\noindent The values of (c), (d) and the final NCC measure are computed in the \emph{CrossCorrelation} method:

\begin{lstlisting}
double cLoaedImTDEpip::CrossCorrelation
	(
	    const Pt2di & aPIm1,
	    int aPx,
	    const cLoaedImTDEpip & aIm2,
	    int aSzW
	)
{
   if (! InsideW(aPIm1,aSzW)) return TheDefCorrel;

   Pt2di aPIm2 = aPIm1 + Pt2di(aPx,0);
   if (! aIm2.InsideW(aPIm2,aSzW)) return TheDefCorrel;

   double aS1 = mTImS1.get(aPIm1);
   double aS2 = aIm2.mTImS1.get(aPIm2);


   double aCov = Covariance(aPIm1,aPx,aIm2,aSzW)  -aS1*aS2;

   double aVar11 = mTImS2.get(aPIm1) - ElSquare(aS1);
   double aVar22 = aIm2.mTImS2.get(aPIm2) - ElSquare(aS2);

   return aCov / sqrt(ElMax(1e-5,aVar11*aVar22));
}


\end{lstlisting}


\subsubsection{Matching without regularization}
Matching without the regularization comes down to finding for each pixel in the left image its parallax in the right image for which the similarity of that pair of pixels is highest.\newline

The matching procedures at each zoom (i.e. resolution) level commence inside the \textbf{cAppliTDEpip} class. For every image of the pair the cLoaedImTDEpip object is instantiated, and the \emph{ComputePx} initiates the parallax calculation.

\begin{lstlisting}
void cAppliTDEpip::DoMatchOneScale(int aZoom,int aSzW)
{
	mCurZoom = aZoom;
	cLoaedImTDEpip aLIm1(*mIm1,aZoom,aSzW);
	cLoaedImTDEpip aLIm2(*mIm2,aZoom,aSzW);

	aLIm1.ComputePx(aLIm2,round_up(mIntPx/aZoom) ,aSzW);
}
\end{lstlisting}

The \emph{ComputePx} creates a \emph{matching envelope} constrained by aTEnvInf and aTEnvSup i.e. a region in the parallax space that will be exploited during matching. Initially the \emph{envelope} is a rectangle constrained by $<-aPxMax,+aPxMax>$, and as the matching proceeds at higher resolution levels, the search space adjusts to the true 3D object scene.

\begin{lstlisting}
void cLoaedImTDEpip::ComputePx
      (
	   cLoaedImTDEpip & aIm2,
	   INT aPxMax,
	   int aSzW
      )
{
	TIm2D<INT2,INT> aTEnvInf(mSz);
	TIm2D<INT2,INT> aTEnvSup(mSz);

	ELISE_COPY(aTEnvInf._the_im.all_pts(),-aPxMax,aTEnvInf._the_im.out());
	ELISE_COPY(aTEnvSup._the_im.all_pts(),1+aPxMax,aTEnvSup._the_im.out());

    ComputePx(aIm2,aTEnvInf,aTEnvSup,aSzW);
}
\end{lstlisting}

The overloaded \emph{ComputePx} does the effective job of computing the NCC on a pair of images. The method iterates over all pixels in the left image, and computes the NCC for every parallax from the range embedded inside aTEnvInf and aTEnvSup. The best parallax (i.e. of highest similarity) is saved to mTPx, while the NCC is stored in mTSc. At each pixel it is verified whether the matching is within the defined region of interest (line 13).

\begin{lstlisting}
	for (aP.x =0 ; aP.x < mSz.x ; aP.x++)
	{
	   for (aP.y =0 ; aP.y < mSz.y ; aP.y++)
	   {
		   int aPxMin = aTEnvInf.get(aP);
		   int aPxMax = aTEnvSup.get(aP);
		   int aBestPax = 0;
		   double aBestCor = TheDefCorrel;

		   for (int aPax = aPxMin ; aPax < aPxMax ; aPax++)
		   {
			   double aCor = TheDefCorrel;
			   if (In3DMasq(aP,aPax,aIm2))
			   {
			      aCor = CrossCorrelation(aP,aPax,aIm2,aSzW);
			      if (aCor > aBestCor)
			      {
				     aBestCor = aCor;
				     aBestPax = aPax;
			      }
		      }
		      /// ONLY WHEN REGULARIZATION ON
		      ///  PRGD 2 : fill the cost
		      aSparsPtr[aP.y][aP.x][aPax].SetOwnCost(ToICost(1-aCor));
		      /// == End PGRD2
	   }
	   mTPx.oset(aP,aBestPax);
	   mTSc.oset(aP,ElMax(0,ElMin(255,round_ni((aBestCor+1)*128))));
	   }
	}

	Tiff_Im::CreateFromIm(mTPx._the_im,"TestPx.tif");
	Tiff_Im::CreateFromIm(mTSc._the_im,"TestSc.tif");

	std::cout << "DONE PX\n";

\end{lstlisting}



\subsubsection{Matching with regularization}
Matching with regularization differs from the example shown above in that the computed parallaxes apart from being conditioned on the NCC values, are conditioned on the parallaxes of neighbouring pixels. The images are parsed into lines, and for every line a \emph{tCelOpt }structure is created. Solving for the optimal parallaxes along that line is done with dynamic programming. In order to avoid the 'streaking' effects that are pertinent to 1D matching, the images are parsed into lines along a number of different directions. The end result is a combination of all directions (so it is a version of Semi-Global Matching).\newline

The optimization is handled by the \textbf{cProg2DOptimiser} class defined in ../culture3d/include/\-im\_tpl/ProgDyn2D.h (see an example of using the optimizer in ../culture3d/src/uti\_phgrm/MICMAC/\-FusionCarteProf.cpp).\newline

First up, an object of the \textbf{cProg2DOptimiser} class is created and is templated with the \textbf{cLoaedImTDEpip} class. The \emph{aSparseVol} is of type cDynTplNappe3D and it stores the matching costs (i.e. the \emph{cube} being the volume between two surfaces that constrain the matching search space). The \emph{cube} is composed of cells -- \emph{tCelNap}, that can be accessed via the \emph{aSparsPtr} pointer variable. The code from line 36 -- 66 is almost identical to matching without regularization. The only novelty is the update of the \emph{cube} in line 58. Note that (i) the cube elements are accessed in a reversed order of the coordinates i.e. Y, X and Z, and (ii) it is the cost rather than the correlation value that is inserted inside the cube.\newline
Having computed the costs for all pixels and parallaxes, the optimization is run in line 67 where the input argument corresponds to the numbers of directions that will be exploited during the matching. Line 69 recovers the final and hopefully most optimal parallaxes from the optimizer, line 70 saves it to an image file.


\begin{lstlisting}
void cLoaedImTDEpip::ComputePx
      (
	   cLoaedImTDEpip & aIm2,
	   TIm2D<INT2,INT>    aTEnvInf,
	   TIm2D<INT2,INT>    aTEnvSup,
	   int aSzW
      )
{

	if (0)
	{
		Video_Win aW = Video_Win::WStd(mSz,2);

		Fonc_Num aF = mIm.in(0);
		for (int aK=0 ; aK<4 ; aK++)
		    aF = MySom(aF,2) / 25;

		ELISE_COPY
		(
		    mIm.all_pts(),
		    rect_min(rect_max(255-aF,3),3),
		    aW.ogray()
		);
		aW.clik_in();

    }

	Pt2di aP;
	///  PRGD 1 : create the object

	cProg2DOptimiser<cLoaedImTDEpip> aPrgD(*this,aTEnvInf._the_im,aTEnvSup._the_im,0,1);
    cDynTplNappe3D<tCelNap> &  aSparseVol = aPrgD.Nappe();
    tCelNap ***  aSparsPtr = aSparseVol.Data() ;
    ///  -- end PRGD 1

	for (aP.x =0 ; aP.x < mSz.x ; aP.x++)
	{
	   for (aP.y =0 ; aP.y < mSz.y ; aP.y++)
	   {
		   int aPxMin = aTEnvInf.get(aP);
		   int aPxMax = aTEnvSup.get(aP);
		   int aBestPax = 0;
		   double aBestCor = TheDefCorrel;

		   for (int aPax = aPxMin ; aPax < aPxMax ; aPax++)
		   {
			   double aCor = TheDefCorrel;
			   if (In3DMasq(aP,aPax,aIm2))
			   {
			      aCor = CrossCorrelation(aP,aPax,aIm2,aSzW);
			      if (aCor > aBestCor)
			      {
				     aBestCor = aCor;
				     aBestPax = aPax;
			      }
		      }
		      ///  PRGD 2 : fill the cost
		      aSparsPtr[aP.y][aP.x][aPax].SetOwnCost(ToICost(1-aCor));
		      /// == End PGRD2
	   }
	   mTPx.oset(aP,aBestPax);
	   mTSc.oset(aP,ElMax(0,ElMin(255,round_ni((aBestCor+1)*128))));
	   }
	}

	/// PRGD3 : run the optim and use the result
	aPrgD.DoOptim(7);
	Im2D_INT2 aSolPrgd(mSz.x,mSz.y);
    aPrgD.TranfereSol(aSolPrgd.data());
    Tiff_Im::CreateFromIm(aSolPrgd,"TestPrgPx.tif");
	///  end PRGD3



	if (1)
	{
		Video_Win aW = Video_Win::WStd(mSz,3);

		ELISE_COPY
		(
		    mTPx._the_im.all_pts(),
		    Min(2,Abs(mTPx._the_im.in()-aSolPrgd.in())),
		    aW.odisc()
		);
		aW.clik_in();

    }

	Tiff_Im::CreateFromIm(mTPx._the_im,"TestPx.tif");
	Tiff_Im::CreateFromIm(mTSc._the_im,"TestSc.tif");

	std::cout << "DONE PX\n";
}


\end{lstlisting}

\noindent Within the regularization phase, the optimizer runs the \emph{DoConnexion} method for every pixel in every direction. The input arguments are
\begin{itemize}
   \item[*] aPIn, aPOut : pixel coordinates of two neighbouring points on the line
   \item[*] aSens ? aRab aMul
   \item[*] Input : a column of cells corresponding to the costs of aPIn computed at different parallaxes
   \item[*] aInZMin, aInZMax : the min and max parallax at aPIn (i.e. the start and the end of the column)
   \item[*] Output : a column of cells corresponding to the costs of aPOut computed at different parallaxes
   \item[*] aOutZMin, aOutZMax : the min and max parallax at aPOut (i.e. the start and the end of the column)
\end{itemize}
First, the connectivity of the current pixel is retrieved (line 13, see definition in ../culture3d/src/util/num.cpp), and further used in assigning the its cost (line 18). Each time the \emph{UpdateCostOneArc} method is called, it adds a connection between the aPOut and the aPIn at the current parallax.


% ComputeIntervaleDelta : compute interval that you see
%template <class TArg> void cProg2DOptimiser<TArg>::DoOptim(int aNbDir)
%       DoOneDirection(aKDir);
%       BalayageOneLine(*aVPt);
%       BalayageOneSens
%       mArg.DoConnexion


\begin{lstlisting}
void cLoaedImTDEpip::DoConnexion
     (
		  const Pt2di & aPIn, const Pt2di & aPOut,
		  ePrgSens aSens,int aRab,int aMul,
		  tCelOpt*Input,int aInZMin,int aInZMax,
		  tCelOpt*Output,int aOutZMin,int aOutZMax
      )
{
	for (int aZ = aOutZMin ; aZ < aOutZMax ; aZ++)
	{
		int aDZMin,aDZMax;
		ComputeIntervaleDelta
		(
		    aDZMin,aDZMax,aZ,mMaxJumpPax,
		    aOutZMin,aOutZMax,
		    aInZMin,aInZMax
		);
	for (int aDZ = aDZMin; aDZ<= aDZMax ; aDZ++)
	{
			double aCost = mRegul * ElAbs(aDZ);
			Output[aZ].UpdateCostOneArc(Input[aZ+aDZ],aSens,ToICost(aCost));
	    }

    }
}
\end{lstlisting}



%---------------------------------------------

